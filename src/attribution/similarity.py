"""
ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡çµ„
æä¾›å¤šç¨®ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•
"""

import numpy as np
from typing import Dict, List, Tuple
from scipy.spatial.distance import cosine, euclidean
from scipy.stats import pearsonr
from loguru import logger


class SimilarityCalculator:
    """
    è¨ˆç®—æŒ‡ç´‹ä¹‹é–“çš„ç›¸ä¼¼åº¦
    æ”¯æŒå¤šç¨®ç›¸ä¼¼åº¦åº¦é‡
    """
    
    def __init__(self):
        self.metrics = [
            "cosine",
            "euclidean",
            "pearson",
            "kl_divergence",
        ]
    
    def cosine_similarity(
        self, 
        vec1: np.ndarray, 
        vec2: np.ndarray
    ) -> float:
        """
        è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        å€¼åŸŸ [-1, 1]ï¼Œè¶Šæ¥è¿‘ 1 è¡¨ç¤ºè¶Šç›¸ä¼¼
        
        Args:
            vec1, vec2: ç‰¹å¾µå‘é‡
        
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸
        """
        if len(vec1) != len(vec2):
            logger.warning(f"å‘é‡ç¶­åº¦ä¸åŒ¹é…: {len(vec1)} vs {len(vec2)}")
            # è£œé½Šè¼ƒçŸ­çš„å‘é‡
            max_len = max(len(vec1), len(vec2))
            vec1 = np.pad(vec1, (0, max_len - len(vec1)), mode='constant')
            vec2 = np.pad(vec2, (0, max_len - len(vec2)), mode='constant')
        
        # ä½¿ç”¨ 1 - cosine_distance å¾—åˆ°ç›¸ä¼¼åº¦
        similarity = 1 - cosine(vec1, vec2)
        
        # è™•ç† NaN
        if np.isnan(similarity):
            return 0.0
        
        return float(similarity)
    
    def euclidean_distance(
        self, 
        vec1: np.ndarray, 
        vec2: np.ndarray
    ) -> float:
        """
        è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢
        è·é›¢è¶Šå°è¡¨ç¤ºè¶Šç›¸ä¼¼
        è¿”å›æ­¸ä¸€åŒ–çš„ç›¸ä¼¼åº¦åˆ†æ•¸ [0, 1]
        """
        if len(vec1) != len(vec2):
            max_len = max(len(vec1), len(vec2))
            vec1 = np.pad(vec1, (0, max_len - len(vec1)), mode='constant')
            vec2 = np.pad(vec2, (0, max_len - len(vec2)), mode='constant')
        
        dist = euclidean(vec1, vec2)
        
        # è½‰æ›ç‚ºç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ RBF kernel æ¦‚å¿µï¼‰
        # similarity = exp(-distance / sigma)
        sigma = np.std(vec1) + np.std(vec2) + 1e-10
        similarity = np.exp(-dist / sigma)
        
        return float(similarity)
    
    def pearson_correlation(
        self, 
        vec1: np.ndarray, 
        vec2: np.ndarray
    ) -> float:
        """
        è¨ˆç®— Pearson ç›¸é—œä¿‚æ•¸
        å€¼åŸŸ [-1, 1]ï¼Œè¶Šæ¥è¿‘ 1 è¡¨ç¤ºæ­£ç›¸é—œè¶Šå¼·
        """
        if len(vec1) != len(vec2):
            max_len = max(len(vec1), len(vec2))
            vec1 = np.pad(vec1, (0, max_len - len(vec1)), mode='constant')
            vec2 = np.pad(vec2, (0, max_len - len(vec2)), mode='constant')
        
        if len(vec1) < 2:
            return 0.0
        
        try:
            corr, _ = pearsonr(vec1, vec2)
            return float(corr) if not np.isnan(corr) else 0.0
        except:
            return 0.0
    
    def kl_divergence(
        self, 
        p: np.ndarray, 
        q: np.ndarray,
        epsilon: float = 1e-10
    ) -> float:
        """
        è¨ˆç®— KL æ•£åº¦ (Kullback-Leibler Divergence)
        ç”¨æ–¼æ¯”è¼ƒå…©å€‹æ©Ÿç‡åˆ†ä½ˆ
        å€¼è¶Šå°è¡¨ç¤ºåˆ†ä½ˆè¶Šç›¸ä¼¼
        
        æ³¨æ„ï¼šKL æ•£åº¦ä¸å°ç¨±ï¼Œé€™è£¡è¨ˆç®—å°ç¨±ç‰ˆæœ¬ (Jensen-Shannon Divergence)
        """
        if len(p) != len(q):
            max_len = max(len(p), len(q))
            p = np.pad(p, (0, max_len - len(p)), mode='constant')
            q = np.pad(q, (0, max_len - len(q)), mode='constant')
        
        # ç¢ºä¿æ˜¯æ©Ÿç‡åˆ†ä½ˆï¼ˆæ­¸ä¸€åŒ–ä¸”éè² ï¼‰
        p = np.abs(p) + epsilon
        q = np.abs(q) + epsilon
        
        p = p / np.sum(p)
        q = q / np.sum(q)
        
        # è¨ˆç®—å°ç¨± KL æ•£åº¦ï¼ˆJensen-Shannon Divergenceï¼‰
        m = 0.5 * (p + q)
        
        kl_pm = np.sum(p * np.log(p / m))
        kl_qm = np.sum(q * np.log(q / m))
        
        js_div = 0.5 * (kl_pm + kl_qm)
        
        # è½‰æ›ç‚ºç›¸ä¼¼åº¦åˆ†æ•¸ [0, 1]
        # JS divergence ç¯„åœæ˜¯ [0, ln(2)]ï¼Œæ‰€ä»¥é™¤ä»¥ ln(2) æ­¸ä¸€åŒ–
        similarity = 1 - (js_div / np.log(2))
        
        return float(np.clip(similarity, 0.0, 1.0))
    
    def calculate_all_metrics(
        self, 
        vec1: np.ndarray, 
        vec2: np.ndarray
    ) -> Dict[str, float]:
        """
        è¨ˆç®—æ‰€æœ‰ç›¸ä¼¼åº¦æŒ‡æ¨™
        
        Returns:
            åŒ…å«æ‰€æœ‰æŒ‡æ¨™çš„å­—å…¸
        """
        results = {
            "cosine_similarity": self.cosine_similarity(vec1, vec2),
            "euclidean_similarity": self.euclidean_distance(vec1, vec2),
            "pearson_correlation": self.pearson_correlation(vec1, vec2),
            "kl_similarity": self.kl_divergence(vec1, vec2),
        }
        
        # è¨ˆç®—ç¶œåˆåˆ†æ•¸ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
        weights = {
            "cosine_similarity": 0.4,
            "euclidean_similarity": 0.2,
            "pearson_correlation": 0.2,
            "kl_similarity": 0.2,
        }
        
        results["ensemble_score"] = sum(
            results[metric] * weight 
            for metric, weight in weights.items()
        )
        
        return results
    
    def compare_refusal_patterns(
        self,
        fp1_refusal: Dict,
        fp2_refusal: Dict
    ) -> Dict[str, float]:
        """
        æ¯”è¼ƒå…©å€‹æ¨¡å‹çš„æ‹’çµ•æ¨¡å¼ç›¸ä¼¼åº¦
        
        Args:
            fp1_refusal, fp2_refusal: æ‹’çµ•æŒ‡ç´‹å­—å…¸
        
        Returns:
            ç›¸ä¼¼åº¦æŒ‡æ¨™
        """
        metrics = {}
        
        # æ¯”è¼ƒæ‹’çµ•ç‡
        rate1 = fp1_refusal.get("refusal_rate", 0.0)
        rate2 = fp2_refusal.get("refusal_rate", 0.0)
        metrics["refusal_rate_similarity"] = 1 - abs(rate1 - rate2)
        
        # æ¯”è¼ƒæ‹’çµ•é¢¨æ ¼åˆ†ä½ˆ
        style_vec1 = np.array([
            fp1_refusal.get("chinese_style_count", 0),
            fp1_refusal.get("western_style_count", 0),
            fp1_refusal.get("mixed_style_count", 0),
        ], dtype=float)
        
        style_vec2 = np.array([
            fp2_refusal.get("chinese_style_count", 0),
            fp2_refusal.get("western_style_count", 0),
            fp2_refusal.get("mixed_style_count", 0),
        ], dtype=float)
        
        if np.sum(style_vec1) > 0 and np.sum(style_vec2) > 0:
            # æ­¸ä¸€åŒ–
            style_vec1 = style_vec1 / np.sum(style_vec1)
            style_vec2 = style_vec2 / np.sum(style_vec2)
            
            metrics["style_distribution_similarity"] = self.cosine_similarity(
                style_vec1, style_vec2
            )
        else:
            metrics["style_distribution_similarity"] = 0.0
        
        # æ¯”è¼ƒæ‹’çµ•æ¨¡å¼é‡ç–Šåº¦
        patterns1 = set(fp1_refusal.get("pattern_distribution", {}).keys())
        patterns2 = set(fp2_refusal.get("pattern_distribution", {}).keys())
        
        if patterns1 or patterns2:
            overlap = len(patterns1 & patterns2)
            union = len(patterns1 | patterns2)
            metrics["pattern_overlap"] = overlap / union if union > 0 else 0.0
        else:
            metrics["pattern_overlap"] = 0.0
        
        # ç¶œåˆç›¸ä¼¼åº¦
        metrics["refusal_ensemble_score"] = np.mean([
            metrics["refusal_rate_similarity"],
            metrics["style_distribution_similarity"],
            metrics["pattern_overlap"],
        ])
        
        return metrics
    
    def calculate_fingerprint_similarity(
        self,
        fp1: Dict,
        fp2: Dict
    ) -> Dict:
        """
        è¨ˆç®—å…©å€‹å®Œæ•´æŒ‡ç´‹çš„ç›¸ä¼¼åº¦
        
        Args:
            fp1, fp2: å®Œæ•´çš„æŒ‡ç´‹å­—å…¸ï¼ˆåŒ…å« logit å’Œ refusalï¼‰
        
        Returns:
            å®Œæ•´çš„ç›¸ä¼¼åº¦åˆ†æ
        """
        result = {
            "logit_similarity": {},
            "refusal_similarity": {},
            "overall_similarity": 0.0,
        }
        
        # æ¯”è¼ƒ Logit æŒ‡ç´‹
        if fp1.get("logit_fingerprint") and fp2.get("logit_fingerprint"):
            vec1 = np.array(fp1["logit_fingerprint"]["vector"])
            vec2 = np.array(fp2["logit_fingerprint"]["vector"])
            
            result["logit_similarity"] = self.calculate_all_metrics(vec1, vec2)
        
        # æ¯”è¼ƒæ‹’çµ•æŒ‡ç´‹
        if fp1.get("refusal_fingerprint") and fp2.get("refusal_fingerprint"):
            result["refusal_similarity"] = self.compare_refusal_patterns(
                fp1["refusal_fingerprint"],
                fp2["refusal_fingerprint"]
            )
        
        # è¨ˆç®—æ•´é«”ç›¸ä¼¼åº¦ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
        logit_score = result["logit_similarity"].get("ensemble_score", 0.0)
        refusal_score = result["refusal_similarity"].get("refusal_ensemble_score", 0.0)
        
        # ğŸ”§ ä¿®å¤ï¼šå¦‚æœæ‹’ç»æŒ‡çº¹ä¸å­˜åœ¨ï¼Œåªä½¿ç”¨ logit åˆ†æ•°
        if fp1.get("refusal_fingerprint") and fp2.get("refusal_fingerprint"):
            # ä¸¤ä¸ªæŒ‡çº¹éƒ½æœ‰æ‹’ç»æ•°æ®ï¼Œä½¿ç”¨åŠ æƒå¹³å‡
            # Logit æŒ‡ç´‹æ¬Šé‡è¼ƒé«˜ï¼ˆ0.7ï¼‰ï¼Œæ‹’çµ•æ¨¡å¼æ¬Šé‡è¼ƒä½ï¼ˆ0.3ï¼‰
            result["overall_similarity"] = 0.7 * logit_score + 0.3 * refusal_score
        else:
            # æ‹’ç»æŒ‡çº¹ç¼ºå¤±ï¼Œåªä½¿ç”¨ logit åˆ†æ•°
            result["overall_similarity"] = logit_score
        
        return result


def main():
    """æ¸¬è©¦ç›¸ä¼¼åº¦è¨ˆç®—å™¨"""
    calc = SimilarityCalculator()
    
    # æ¸¬è©¦å‘é‡
    vec1 = np.random.randn(100)
    vec2 = vec1 + np.random.randn(100) * 0.1  # ç›¸ä¼¼å‘é‡
    vec3 = np.random.randn(100)  # ä¸ç›¸ä¼¼å‘é‡
    
    print("ç›¸ä¼¼åº¦è¨ˆç®—å™¨æ¸¬è©¦:")
    print("=" * 60)
    
    print("\næ¸¬è©¦1: ç›¸ä¼¼å‘é‡ (vec1 vs vec2)")
    metrics = calc.calculate_all_metrics(vec1, vec2)
    for metric, score in metrics.items():
        print(f"  {metric}: {score:.4f}")
    
    print("\næ¸¬è©¦2: ä¸ç›¸ä¼¼å‘é‡ (vec1 vs vec3)")
    metrics = calc.calculate_all_metrics(vec1, vec3)
    for metric, score in metrics.items():
        print(f"  {metric}: {score:.4f}")


if __name__ == "__main__":
    main()
