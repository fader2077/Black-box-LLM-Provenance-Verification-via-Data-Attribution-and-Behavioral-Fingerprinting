# é”šç‚¹æ¨¡å‹é…ç½®è¯´æ˜

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•æ·»åŠ ã€ä¿®æ”¹æˆ–åˆ é™¤é”šç‚¹æ¨¡å‹ã€‚

---

## é”šç‚¹æ¨¡å‹é…ç½®ä½ç½®

é”šç‚¹æ¨¡å‹é…ç½®åœ¨ä»¥ä¸‹æ–‡ä»¶ä¸­ï¼š

### 1. `data/anchor_models/metadata.json`

è¿™æ˜¯**ä¸»è¦é…ç½®æ–‡ä»¶**ï¼Œå®šä¹‰äº†æ‰€æœ‰é”šç‚¹æ¨¡å‹çš„å…ƒæ•°æ®ã€‚

**æ–‡ä»¶è·¯å¾„**: `data/anchor_models/metadata.json`

**ç»“æ„ç¤ºä¾‹**:
```json
{
  "anchors": [
    {
      "name": "gpt2",
      "family": "gpt",
      "source": "openai",
      "fingerprint_file": "data/anchor_models/gpt2_fingerprint.json",
      "description": "GPT-2 base model",
      "size": "124M parameters"
    },
    {
      "name": "deepseek-r1:7b",
      "family": "deepseek",
      "source": "china",
      "fingerprint_file": "data/anchor_models/deepseek_r1_7b_fingerprint.json",
      "description": "DeepSeek-R1 7B model",
      "size": "7B parameters"
    }
  ],
  "last_updated": "2026-02-04T07:00:00",
  "version": "1.0"
}
```

### 2. `src/attribution/anchor_models.py`

è¿™ä¸ªæ–‡ä»¶ä¸­çš„ `_load_database()` å‡½æ•°ä» `metadata.json` è¯»å–é…ç½®ã€‚

**å…³é”®ä»£ç **:
```python
def _load_database(db_path: str) -> List[Dict]:
    """ä»æ•°æ®åº“ç›®å½•åŠ è½½æ‰€æœ‰é”šç‚¹æ¨¡å‹"""
    metadata_file = Path(db_path) / "metadata.json"
    
    if metadata_file.exists():
        with open(metadata_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('anchors', [])
```

---

## å¦‚ä½•æ·»åŠ æ–°é”šç‚¹æ¨¡å‹

### æ­¥éª¤ 1: æå–æŒ‡çº¹

ä½¿ç”¨è¶…ç¨³å¥æå–å·¥å…·æå–æ–°æ¨¡å‹çš„æŒ‡çº¹ï¼š

```bash
# ç¤ºä¾‹ï¼šæ·»åŠ  Llama-3.1-8B é”šç‚¹
python experiments/ultra_robust_extraction.py \
  --model llama3.1:8b \
  --engine ollama \
  --num-probes 30 \
  --probes-per-session 3 \
  --rest-time 4 \
  --device cuda \
  --output data/anchor_models/llama3_1_8b_fingerprint.json
```

**å‚æ•°è¯´æ˜**:
- `--model`: æ¨¡å‹åç§°ï¼ˆOllamaæ¨¡å‹æˆ–HuggingFaceè·¯å¾„ï¼‰
- `--engine`: æ¨ç†å¼•æ“ï¼ˆ`ollama` æˆ– `transformers`ï¼‰
- `--num-probes`: æ¢é’ˆæ•°é‡ï¼ˆå»ºè®®30-100ï¼‰
- `--probes-per-session`: æ¯Nä¸ªæ¢é’ˆé‡æ–°åŠ è½½æ¨¡å‹ï¼ˆå»ºè®®3ï¼‰
- `--rest-time`: æ¢é’ˆé—´ä¼‘æ¯æ—¶é—´ï¼ˆç§’ï¼‰
- `--device`: è®¾å¤‡ï¼ˆ`cuda` æˆ– `cpu`ï¼‰
- `--output`: è¾“å‡ºæŒ‡çº¹æ–‡ä»¶è·¯å¾„

### æ­¥éª¤ 2: æ›´æ–° metadata.json

ç¼–è¾‘ `data/anchor_models/metadata.json`ï¼Œåœ¨ `anchors` æ•°ç»„ä¸­æ·»åŠ æ–°æ¡ç›®ï¼š

```json
{
  "anchors": [
    // ... ç°æœ‰é”šç‚¹ ...
    {
      "name": "llama3.1:8b",
      "family": "llama",
      "source": "meta",
      "fingerprint_file": "data/anchor_models/llama3_1_8b_fingerprint.json",
      "description": "Llama-3.1-8B instruction tuned model",
      "size": "8B parameters"
    }
  ],
  "last_updated": "2026-02-04T08:20:00",
  "version": "1.1"
}
```

**å­—æ®µè¯´æ˜**:
- `name`: æ¨¡å‹æ˜¾ç¤ºåç§°
- `family`: æ¨¡å‹å®¶æ—ï¼ˆ`llama`, `deepseek`, `gpt`, `qwen` ç­‰ï¼‰
- `source`: æ¥æºç»„ç»‡ï¼ˆ`meta`, `china`, `openai` ç­‰ï¼‰
- `fingerprint_file`: æŒ‡çº¹æ–‡ä»¶çš„ç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„
- `description`: æ¨¡å‹æè¿°ï¼ˆå¯é€‰ï¼‰
- `size`: å‚æ•°é‡ï¼ˆå¯é€‰ï¼‰

### æ­¥éª¤ 3: éªŒè¯é…ç½®

è¿è¡Œæµ‹è¯•ä»¥ç¡®ä¿æ–°é”šç‚¹æ­£ç¡®åŠ è½½ï¼š

```bash
python -c "
from src.attribution.anchor_models import load_anchor_database
anchors = load_anchor_database('data/anchor_models')
for anchor in anchors:
    print(f'âœ“ {anchor[\"name\"]:20} {anchor[\"family\"]:10} {anchor[\"source\"]}')
"
```

---

## å¦‚ä½•åˆ é™¤é”šç‚¹æ¨¡å‹

### æ–¹æ³• 1: ä» metadata.json ä¸­ç§»é™¤

ç¼–è¾‘ `data/anchor_models/metadata.json`ï¼Œåˆ é™¤å¯¹åº”çš„é”šç‚¹æ¡ç›®ï¼š

```json
{
  "anchors": [
    // åˆ é™¤ä¸éœ€è¦çš„é”šç‚¹æ¡ç›®
    {
      "name": "qwen2.5:7b",  // <-- åˆ é™¤è¿™æ•´ä¸ªå¯¹è±¡
      ...
    }
  ]
}
```

### æ–¹æ³• 2: åˆ é™¤æŒ‡çº¹æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

å¦‚æœè¦å½»åº•æ¸…ç†ï¼Œä¹Ÿåˆ é™¤å¯¹åº”çš„æŒ‡çº¹æ–‡ä»¶ï¼š

```bash
rm data/anchor_models/qwen2_5_7b_fingerprint.json
```

---

## å¦‚ä½•ä¿®æ”¹é”šç‚¹å±æ€§

ç›´æ¥ç¼–è¾‘ `metadata.json` ä¸­çš„ç›¸åº”å­—æ®µï¼š

**ç¤ºä¾‹ï¼šæ›´æ”¹å®¶æ—åˆ†ç±»**
```json
{
  "name": "deepseek-r1:7b",
  "family": "deepseek",  // ä¿®æ”¹æ­¤å­—æ®µ
  "source": "china",     // æˆ–ä¿®æ”¹æ­¤å­—æ®µ
  ...
}
```

---

## é”šç‚¹æ¨¡å‹å‘½åè§„èŒƒ

### æ–‡ä»¶å‘½å
- **æŒ‡çº¹æ–‡ä»¶**: `{model_name}_fingerprint.json`
- **ç¤ºä¾‹**: 
  - `gpt2_fingerprint.json`
  - `llama3_1_8b_fingerprint.json`
  - `deepseek_r1_7b_fingerprint.json`

### æ¨¡å‹åç§°
- ä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿
- Ollamaæ¨¡å‹ä¿ç•™åŸåæ ¼å¼ï¼ˆå¦‚ `llama3.1:8b`ï¼‰
- HuggingFaceæ¨¡å‹ç®€åŒ–åç§°ï¼ˆå¦‚ `gpt2-medium` â†’ `gpt2_medium`ï¼‰

---

## å®Œæ•´ç¤ºä¾‹ï¼šæ·»åŠ  Qwen-2.5-7B é”šç‚¹

### 1. æå–æŒ‡çº¹
```bash
python experiments/ultra_robust_extraction.py \
  --model qwen2.5:7b \
  --engine ollama \
  --num-probes 30 \
  --device cuda \
  --output data/anchor_models/qwen2_5_7b_fingerprint.json
```

### 2. æ›´æ–°é…ç½®
ç¼–è¾‘ `data/anchor_models/metadata.json`:
```json
{
  "anchors": [
    {
      "name": "qwen2.5:7b",
      "family": "qwen",
      "source": "china",
      "fingerprint_file": "data/anchor_models/qwen2_5_7b_fingerprint.json",
      "description": "Qwen-2.5-7B instruction tuned model"
    }
  ]
}
```

### 3. æµ‹è¯•
```bash
python experiments/full_evaluation.py \
  --target-model deepseek-r1:8b \
  --engine ollama
```

---

## å½“å‰é”šç‚¹æ¨¡å‹åˆ—è¡¨

| æ¨¡å‹åç§° | å®¶æ— | æ¥æº | æŒ‡çº¹æ–‡ä»¶ | çŠ¶æ€ |
|---------|------|------|---------|------|
| gpt2 | gpt | openai | gpt2_fingerprint.json | âœ… |
| gpt2-medium | gpt | openai | gpt2_medium_fingerprint.json | âš ï¸ ç¼ºå¤± |
| deepseek-r1:7b | deepseek | china | deepseek_r1_7b_fingerprint.json | âœ… |
| llama3.2:3b | llama | meta | llama3_2_3b_fingerprint.json | âœ… |
| llama3.1:8b | llama | meta | llama3_1_8b_fingerprint.json | ğŸ”„ æå–ä¸­ |

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: "æœªæ‰¾åˆ°é”šç‚¹æ¨¡å‹"

**åŸå› **: `metadata.json` è·¯å¾„é”™è¯¯æˆ–æ ¼å¼ä¸æ­£ç¡®

**è§£å†³**: æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸ºæœ‰æ•ˆ JSONï¼Œè·¯å¾„æ˜¯å¦æ­£ç¡®

### é—®é¢˜ 2: ç›¸ä¼¼åº¦å¼‚å¸¸ä½ï¼ˆ< 20%ï¼‰

**åŸå› **: 
- æ¢é’ˆæ•°é‡ä¸è¶³
- æŒ‡çº¹ç»´åº¦ä¸åŒ¹é…
- ä½¿ç”¨äº†ä¸åŒçš„æå–æ–¹æ³•

**è§£å†³**: 
- ç¡®ä¿æ‰€æœ‰é”šç‚¹ä½¿ç”¨ç›¸åŒçš„æ¢é’ˆæ•°é‡
- ä½¿ç”¨ `ultra_robust_extraction.py` ç»Ÿä¸€æå–
- å»ºè®®è‡³å°‘30ä¸ªæ¢é’ˆ

### é—®é¢˜ 3: "æŒ‡çº¹æ–‡ä»¶ä¸å­˜åœ¨"

**åŸå› **: æŒ‡çº¹æ–‡ä»¶æœªç”Ÿæˆæˆ–è·¯å¾„é”™è¯¯

**è§£å†³**: 
1. æ£€æŸ¥ `fingerprint_file` è·¯å¾„æ˜¯å¦æ­£ç¡®
2. é‡æ–°è¿è¡Œæå–å‘½ä»¤
3. éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼š`ls data/anchor_models/*_fingerprint.json`

---

## æŠ€æœ¯ç»†èŠ‚

### æŒ‡çº¹æ–‡ä»¶æ ¼å¼

```json
{
  "model_name": "llama3.1:8b",
  "timestamp": "2026-02-04 08:20:00",
  "logit_fingerprint": {
    "vector": [0.1, 0.2, ..., 0.5],  // é•¿åº¦ = num_probes Ã— 20
    "dimension": 200,
    "stats": {
      "mean": 0.05,
      "std": 0.02,
      "min": 0.0,
      "max": 0.15
    }
  },
  "extraction_stats": {
    "total_probes": 10,
    "successful_probes": 10,
    "failed_probes": 0,
    "success_rate": 1.0
  }
}
```

### ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•

ç³»ç»Ÿä½¿ç”¨å¤šç§ç›¸ä¼¼åº¦åº¦é‡çš„å¹³å‡å€¼ï¼š
- Cosine ç›¸ä¼¼åº¦
- Pearson ç›¸å…³ç³»æ•°
- æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆå½’ä¸€åŒ–ï¼‰

**æ³¨æ„**: 
- `full_evaluation.py` ä½¿ç”¨å®Œæ•´1110ç»´æŒ‡çº¹ï¼ˆ438æ¢é’ˆ Ã— ~20ç»´/æ¢é’ˆï¼‰
- `ultra_robust_extraction.py` ä½¿ç”¨å¯é…ç½®çš„æ¢é’ˆæ•°ï¼ˆå¦‚30æ¢é’ˆ = 600ç»´ï¼‰
- ç»´åº¦ä¸åŒ¹é…æ—¶ä¼šè‡ªåŠ¨é›¶å¡«å……å¯¹é½

---

## æœ€ä½³å®è·µ

1. **ç»Ÿä¸€æå–æ–¹æ³•**: æ‰€æœ‰é”šç‚¹ä½¿ç”¨ç›¸åŒçš„æå–å·¥å…·å’Œå‚æ•°
2. **è¶³å¤Ÿçš„æ¢é’ˆ**: è‡³å°‘30ä¸ªæ¢é’ˆï¼Œæ¨è50-100ä¸ª
3. **å®šæœŸæ›´æ–°**: æ¨¡å‹æ›´æ–°æ—¶é‡æ–°æå–æŒ‡çº¹
4. **å¤‡ä»½é…ç½®**: ä¿®æ”¹å‰å¤‡ä»½ `metadata.json`
5. **éªŒè¯å®Œæ•´æ€§**: æå–åè¿è¡Œæµ‹è¯•éªŒè¯

---

## ç›¸å…³æ–‡ä»¶

- é”šç‚¹é…ç½®: `data/anchor_models/metadata.json`
- é”šç‚¹åŠ è½½: `src/attribution/anchor_models.py`
- æå–å·¥å…·: `experiments/ultra_robust_extraction.py`
- å®Œæ•´è¯„ä¼°: `experiments/full_evaluation.py`
- å¿«é€Ÿåˆ†æ: `quick_similarity_analysis.py`

---

**æœ€åæ›´æ–°**: 2026å¹´2æœˆ4æ—¥  
**ç‰ˆæœ¬**: 1.0
