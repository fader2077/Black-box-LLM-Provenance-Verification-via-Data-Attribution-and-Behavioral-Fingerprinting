"""
ä½¿ç”¨ç°æœ‰æœ‰æ•ˆé”šç‚¹æµ‹è¯•ç›®æ ‡æ¨¡å‹
ä»…ä½¿ç”¨æœ‰çœŸå®logitsçš„é”šç‚¹: GPT2, GPT2-Medium, DeepSeek-R1:7b
"""
import json
from pathlib import Path
from loguru import logger
import numpy as np

def load_fingerprint(fp_path):
    """åŠ è½½æŒ‡çº¹æ–‡ä»¶"""
    with open(fp_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return np.array(data['logit_fingerprint']['vector'])

def cosine_similarity(v1, v2):
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    # å¯¹é½ç»´åº¦
    min_len = min(len(v1), len(v2))
    v1 = v1[:min_len]
    v2 = v2[:min_len]
    
    dot_product = np.dot(v1, v2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    
    if norm_v1 == 0 or norm_v2 == 0:
        return 0.0
    
    return dot_product / (norm_v1 * norm_v2)

# æœ‰æ•ˆé”šç‚¹ï¼ˆæœ‰çœŸå®logitsï¼‰
anchors = {
    "gpt2": {
        "path": "data/anchor_models/gpt2_fingerprint.json",
        "family": "gpt",
        "source": "openai"
    },
    "gpt2-medium": {
        "path": "data/anchor_models/gpt2_medium_fingerprint.json",
        "family": "gpt",
        "source": "openai"
    },
    "deepseek-r1:7b": {
        "path": "data/anchor_models/deepseek_r1_7b_fingerprint.json",
        "family": "deepseek",
        "source": "china"
    }
}

# ç›®æ ‡æ¨¡å‹
target_model = "deepseek-r1:8b-llama-distill"
target_path = "results/deepseek-r1_8b-llama-distill-q4_K_M_fingerprint.json"

logger.info("=" * 70)
logger.info("ä½¿ç”¨æœ‰æ•ˆé”šç‚¹æµ‹è¯•ç›®æ ‡æ¨¡å‹")
logger.info("=" * 70)

# æ£€æŸ¥ç›®æ ‡æŒ‡çº¹æ˜¯å¦å­˜åœ¨
if not Path(target_path).exists():
    logger.error(f"ç›®æ ‡æŒ‡çº¹ä¸å­˜åœ¨: {target_path}")
    logger.info("è¯·å…ˆè¿è¡Œ: python experiments/full_evaluation.py --target-model deepseek-r1:8b-llama-distill-q4_K_M --engine ollama")
    exit(1)

# åŠ è½½ç›®æ ‡æŒ‡çº¹
logger.info(f"\nåŠ è½½ç›®æ ‡æ¨¡å‹æŒ‡çº¹: {target_model}")
target_fp = load_fingerprint(target_path)
logger.info(f"  ç»´åº¦: {len(target_fp)}")
logger.info(f"  èŒƒå›´: [{target_fp.min():.3f}, {target_fp.max():.3f}]")

# æ£€æŸ¥ç›®æ ‡æŒ‡çº¹æ˜¯å¦æœ‰æ•ˆ
if target_fp.max() == 0 and target_fp.min() == 0:
    logger.error("âš ï¸ ç›®æ ‡æŒ‡çº¹å…¨ä¸º0ï¼ˆå¯å‘å¼ç‰¹å¾ï¼‰ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆæ¯”è¾ƒ")
    logger.info("å»ºè®®ä½¿ç”¨ transformers å¼•æ“é‡æ–°æå–")
    exit(1)

# è®¡ç®—ä¸å„é”šç‚¹çš„ç›¸ä¼¼åº¦
logger.info("\n" + "=" * 70)
logger.info("ç›¸ä¼¼åº¦åˆ†æ")
logger.info("=" * 70)

similarities = []

for anchor_name, anchor_info in anchors.items():
    anchor_path = Path(anchor_info['path'])
    
    if not anchor_path.exists():
        logger.warning(f"é”šç‚¹æŒ‡çº¹ä¸å­˜åœ¨: {anchor_path}")
        continue
    
    # åŠ è½½é”šç‚¹æŒ‡çº¹
    anchor_fp = load_fingerprint(anchor_path)
    
    # æ£€æŸ¥é”šç‚¹æŒ‡çº¹æ˜¯å¦æœ‰æ•ˆ
    if anchor_fp.max() == 0 and anchor_fp.min() == 0:
        logger.warning(f"âš ï¸ {anchor_name} æŒ‡çº¹å…¨ä¸º0ï¼Œè·³è¿‡")
        continue
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarity = cosine_similarity(target_fp, anchor_fp)
    
    similarities.append({
        "anchor": anchor_name,
        "family": anchor_info['family'],
        "source": anchor_info['source'],
        "similarity": similarity
    })
    
    logger.info(f"\n{anchor_name:25} [{anchor_info['family']:10}]")
    logger.info(f"  ç›¸ä¼¼åº¦: {similarity:.4f}")
    logger.info(f"  é”šç‚¹ç»´åº¦: {len(anchor_fp)}")

# æ’åºå¹¶æ˜¾ç¤ºç»“æœ
logger.info("\n" + "=" * 70)
logger.info("æœ€ç»ˆç»“æœ")
logger.info("=" * 70)

similarities.sort(key=lambda x: x['similarity'], reverse=True)

print("\nç›¸ä¼¼åº¦æ’å:")
for i, sim in enumerate(similarities, 1):
    emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else ""
    print(f"{i}. {sim['anchor']:25} [{sim['family']:10}]  {sim['similarity']:.4f}  {emoji}")

# åˆ¤å®š
if similarities:
    best = similarities[0]
    second_best = similarities[1] if len(similarities) > 1 else None
    
    print(f"\nç»“è®º:")
    if second_best:
        diff_pct = (best['similarity'] - second_best['similarity']) / second_best['similarity'] * 100
        print(f"  {target_model} ä¸ {best['family']} å®¶æ—ç›¸ä¼¼åº¦æœ€é«˜")
        print(f"  æ¯”ç¬¬äºŒåé«˜ {diff_pct:.2f}%")
    else:
        print(f"  {target_model} ä¸ {best['family']} å®¶æ—æœ€ç›¸ä¼¼")
    
    print(f"\n  æœ€é«˜ç›¸ä¼¼åº¦: {best['similarity']:.4f}")
    print(f"  å®¶æ—: {best['family']}")
    print(f"  æ¥æº: {best['source']}")
    
    # ç½®ä¿¡åº¦è¯„ä¼°
    if best['similarity'] > 0.8:
        confidence = "æé«˜"
    elif best['similarity'] > 0.6:
        confidence = "é«˜"
    elif best['similarity'] > 0.4:
        confidence = "ä¸­ç­‰"
    else:
        confidence = "ä½"
    
    print(f"  ç½®ä¿¡åº¦: {confidence}")

logger.info("\n" + "=" * 70)
logger.info("æ³¨æ„äº‹é¡¹")
logger.info("=" * 70)
logger.info("âœ… æ­¤æ¬¡æµ‹è¯•ä½¿ç”¨äº†æœ‰çœŸå®logitsçš„é”šç‚¹")
logger.info("âš ï¸ æœªåŒ…å«Llamaç³»åˆ—é”šç‚¹ï¼ˆOllamaä¸æ”¯æŒlogprobsï¼‰")
logger.info("ğŸ’¡ è‹¥éœ€æ›´å‡†ç¡®ç»“æœï¼Œå»ºè®®ä½¿ç”¨HuggingFace transformerså¼•æ“")
