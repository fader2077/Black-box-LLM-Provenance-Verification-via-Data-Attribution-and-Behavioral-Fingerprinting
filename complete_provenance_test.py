"""
å®Œæ•´è°±ç³»åˆ¤å®šæµ‹è¯• - DeepSeek-R1-Distill-Llama-8B
æµ‹è¯•ç›®æ ‡ï¼šåˆ¤å®šæ¨¡å‹æ˜¯å±äº Llama è¿˜æ˜¯ DeepSeek å®¶æ—
"""

import sys
import json
import subprocess
import time
from pathlib import Path
from loguru import logger

logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
    level="INFO"
)


class ComprehensiveProvenanceTest:
    """å®Œæ•´è°±ç³»åˆ¤å®šæµ‹è¯•"""
    
    def __init__(self):
        self.ultra_robust = "experiments/ultra_robust_extraction.py"
        self.results = []
    
    def run_extraction(self, model_name: str, output_file: str, num_probes: int = 1500) -> bool:
        """è¿è¡ŒæŒ‡çº¹æå–"""
        logger.info(f"\n{'='*70}")
        logger.info(f"æå–æŒ‡çº¹: {model_name}")
        logger.info(f"{'='*70}")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if Path(output_file).exists():
            logger.info(f"âœ“ æŒ‡çº¹æ–‡ä»¶å·²å­˜åœ¨: {output_file}")
            return True
        
        cmd = [
            "python", self.ultra_robust,
            "--model", model_name,
            "--engine", "ollama",
            "--num-probes", str(num_probes),
            "--probes-per-session", "3",
            "--rest-time", "4",
            "--device", "cuda",
            "--output", output_file
        ]
        
        try:
            logger.info(f"è¿è¡Œ: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=False, timeout=num_probes * 20)
            
            if result.returncode == 0 and Path(output_file).exists():
                logger.success(f"âœ“ {model_name} æå–æˆåŠŸ")
                return True
            else:
                logger.error(f"âœ— {model_name} æå–å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âœ— æå–å¼‚å¸¸: {e}")
            return False
    
    def check_anchors(self) -> dict:
        """æ£€æŸ¥é”šç‚¹æ¨¡å‹çŠ¶æ€"""
        logger.info("\næ£€æŸ¥é”šç‚¹æ¨¡å‹...")
        
        anchors = {
            "gpt": {
                "gpt2": "data/anchor_models_transformers/gpt2_fingerprint.json",
                "gpt2-medium": "data/anchor_models_transformers/gpt2_medium_fingerprint.json"
            },
            "deepseek": {
                "deepseek-r1:7b": "data/anchor_models/deepseek-r1_7b_fingerprint.json"
            },
            "llama": {
                "llama3.2:3b": "data/anchor_models/llama3_2_3b_fingerprint.json"
            }
        }
        
        status = {}
        for family, models in anchors.items():
            status[family] = {}
            for name, path in models.items():
                exists = Path(path).exists()
                status[family][name] = {
                    "path": path,
                    "exists": exists
                }
                
                symbol = "âœ“" if exists else "âœ—"
                logger.info(f"  {symbol} {family:10} {name:20} {path}")
        
        return status
    
    def ensure_llama_anchor(self) -> bool:
        """ç¡®ä¿ Llama é”šç‚¹å­˜åœ¨"""
        llama_fp = "data/anchor_models/llama3_2_3b_fingerprint.json"
        
        if Path(llama_fp).exists():
            logger.success("âœ“ Llama é”šç‚¹å·²å­˜åœ¨")
            return True
        
        logger.info("æå– Llama é”šç‚¹...")
        return self.run_extraction("llama3.2:3b", llama_fp, num_probes=30)
    
    def extract_target_model(self) -> bool:
        """æå–ç›®æ ‡æ¨¡å‹æŒ‡çº¹"""
        target_model = "deepseek-r1:8b-llama-distill-q4_K_M"
        output_file = "results/deepseek_r1_distill_llama_8b_fingerprint.json"
        
        logger.info(f"\n{'='*70}")
        logger.info("æå–ç›®æ ‡æ¨¡å‹: DeepSeek-R1-Distill-Llama-8B")
        logger.info(f"{'='*70}")
        
        return self.run_extraction(target_model, output_file, num_probes=30)
    
    def run_similarity_analysis(self) -> dict:
        """è¿è¡Œç›¸ä¼¼åº¦åˆ†æ"""
        logger.info(f"\n{'='*70}")
        logger.info("ç›¸ä¼¼åº¦åˆ†æ")
        logger.info(f"{'='*70}")
        
        try:
            # ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½®ç¼–ç 
            import os
            os.environ['PYTHONIOENCODING'] = 'utf-8'
            
            result = subprocess.run(
                ["python", "quick_similarity_analysis.py"],
                capture_output=True,
                text=True,
                timeout=60,
                encoding='utf-8'
            )
            
            if result.returncode == 0:
                logger.success("âœ“ ç›¸ä¼¼åº¦åˆ†æå®Œæˆ")
                print(result.stdout)
                
                # è§£æç»“æœ
                result_file = Path("results/quick_analysis_result.json")
                if result_file.exists():
                    with open(result_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
                        
            else:
                logger.error("âœ— ç›¸ä¼¼åº¦åˆ†æå¤±è´¥")
                print(result.stderr)
                
        except Exception as e:
            logger.error(f"âœ— åˆ†æå¼‚å¸¸: {e}")
        
        return None
    
    def verify_gpu_usage(self):
        """éªŒè¯GPUä½¿ç”¨"""
        logger.info("\næ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ...")
        
        try:
            result = subprocess.run(
                ["ollama", "ps"],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                output = result.stdout
                logger.info("OllamaçŠ¶æ€:")
                for line in output.strip().split('\n'):
                    logger.info(f"  {line}")
                
                if "GPU" in output:
                    logger.success("âœ“ ç¡®è®¤ä½¿ç”¨GPU")
                    return True
                else:
                    logger.warning("âš  æœªæ£€æµ‹åˆ°GPUä½¿ç”¨")
                    
        except Exception as e:
            logger.error(f"GPUæ£€æŸ¥å¤±è´¥: {e}")
        
        return False
    
    def generate_final_report(self, similarity_results: dict):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        logger.info(f"\n{'='*70}")
        logger.info("æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š")
        logger.info(f"{'='*70}")
        
        if not similarity_results:
            logger.error("æ— ç›¸ä¼¼åº¦ç»“æœï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return
        
        # æå–å…³é”®ä¿¡æ¯
        target = similarity_results.get('target_model', 'unknown')
        similarities = similarity_results.get('similarities', [])
        
        logger.info(f"\nç›®æ ‡æ¨¡å‹: {target}")
        logger.info(f"\nç›¸ä¼¼åº¦æ’å:")
        
        for i, sim in enumerate(similarities[:5], 1):
            model = sim.get('model', 'unknown')
            family = sim.get('family', 'unknown')
            score = sim.get('similarity', 0)
            
            medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "", ""][i-1] if i <= 3 else ""
            logger.info(f"{i}. {model:25} [{family:10}] {score:.4f} {medal}")
        
        # ç±»åˆ«ç»Ÿè®¡
        category_avg = similarity_results.get('category_average', {})
        if category_avg:
            logger.info(f"\nç±»åˆ«å¹³å‡ç›¸ä¼¼åº¦:")
            
            sorted_cats = sorted(category_avg.items(), key=lambda x: x[1], reverse=True)
            for family, avg_score in sorted_cats:
                logger.info(f"  {family:15} {avg_score:.4f}")
        
        # åˆ¤å®šç»“è®º
        if similarities:
            top_model = similarities[0]
            top_family = top_model.get('family', 'unknown')
            top_score = top_model.get('similarity', 0)
            
            logger.info(f"\n{'='*70}")
            logger.success(f"âœ… åˆ¤å®šç»“è®º: DeepSeek-R1-Distill-Llama-8B å±äº {top_family.upper()} å®¶æ—")
            logger.info(f"   æœ€é«˜ç›¸ä¼¼åº¦: {top_model.get('model')} ({top_score:.4f})")
            logger.info(f"{'='*70}")
    
    def run_comprehensive_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        logger.info("\n" + "="*70)
        logger.info("DeepSeek-R1-Distill-Llama-8B å®Œæ•´è°±ç³»åˆ¤å®šæµ‹è¯•")
        logger.info("="*70)
        
        # 1. æ£€æŸ¥é”šç‚¹çŠ¶æ€
        anchor_status = self.check_anchors()
        
        # 2. ç¡®ä¿ Llama é”šç‚¹å­˜åœ¨ï¼ˆå…³é”®ï¼ï¼‰
        if not self.ensure_llama_anchor():
            logger.error("âœ— æ— æ³•è·å– Llama é”šç‚¹ï¼Œæµ‹è¯•ä¸­æ­¢")
            return False
        
        # 3. æå–ç›®æ ‡æ¨¡å‹æŒ‡çº¹
        if not self.extract_target_model():
            logger.error("âœ— ç›®æ ‡æ¨¡å‹æå–å¤±è´¥ï¼Œæµ‹è¯•ä¸­æ­¢")
            return False
        
        # çŸ­æš‚ä¼‘æ¯
        logger.info("\nä¼‘æ¯10ç§’...")
        time.sleep(10)
        
        # 4. è¿è¡Œç›¸ä¼¼åº¦åˆ†æ
        similarity_results = self.run_similarity_analysis()
        
        # 5. éªŒè¯GPUä½¿ç”¨
        self.verify_gpu_usage()
        
        # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        if similarity_results:
            self.generate_final_report(similarity_results)
        
        return True


def main():
    tester = ComprehensiveProvenanceTest()
    
    try:
        success = tester.run_comprehensive_test()
        
        if success:
            logger.success("\nâœ“ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        else:
            logger.error("\nâœ— æµ‹è¯•æœªå®Œå…¨é€šè¿‡")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.warning("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        raise


if __name__ == "__main__":
    main()
