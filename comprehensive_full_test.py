# -*- coding: utf-8 -*-
"""
å…¨é¢ç³»ç»Ÿæµ‹è¯•
æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å’Œå·¥ä½œæµç¨‹
"""
import sys
import json
from pathlib import Path
from loguru import logger

# é…ç½® logger
logger.remove()
logger.add(sys.stderr, level="INFO")
logger.add("comprehensive_test.log", level="DEBUG", encoding="utf-8")

def test_probe_loading():
    """æµ‹è¯•æ¢é’ˆåŠ è½½"""
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯• 1: æ¢é’ˆåŠ è½½")
    logger.info("="*80)
    
    try:
        from src.probes import ProbeGenerator
        
        # åŠ è½½ç¼“å­˜çš„æ¢é’ˆ
        probe_file = Path("data/probes/all_probes.json")
        if not probe_file.exists():
            logger.error(f"æ¢é’ˆæ–‡ä»¶ä¸å­˜åœ¨: {probe_file}")
            return False
        
        with open(probe_file, 'r', encoding='utf-8') as f:
            probes = json.load(f)
        
        logger.info(f"âœ“ æˆåŠŸåŠ è½½ {len(probes)} ä¸ªæ¢é’ˆ")
        
        # æ£€æŸ¥ probe_type å­—æ®µ
        probes_with_type = [p for p in probes if 'probe_type' in p]
        logger.info(f"âœ“ æœ‰ probe_type å­—æ®µçš„æ¢é’ˆ: {len(probes_with_type)}/{len(probes)}")
        
        # ç»Ÿè®¡å„ç±»å‹æ¢é’ˆæ•°é‡
        type_counts = {}
        for probe in probes:
            probe_type = probe.get('probe_type', 'unknown')
            type_counts[probe_type] = type_counts.get(probe_type, 0) + 1
        
        logger.info("æ¢é’ˆç±»å‹åˆ†å¸ƒ:")
        for ptype, count in type_counts.items():
            logger.info(f"  {ptype:30s}: {count:4d}")
        
        return len(probes) == 438 and len(probes_with_type) >= 400
        
    except Exception as e:
        logger.error(f"âœ— æ¢é’ˆåŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_anchor_database():
    """æµ‹è¯•é”šç‚¹æ¨¡å‹æ•°æ®åº“"""
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯• 2: é”šç‚¹æ¨¡å‹æ•°æ®åº“")
    logger.info("="*80)
    
    try:
        from src.attribution.anchor_models import AnchorDatabase
        
        db = AnchorDatabase()
        anchors = db.list_anchors()
        
        logger.info(f"âœ“ æ•°æ®åº“ä¸­æœ‰ {len(anchors)} ä¸ªé”šç‚¹æ¨¡å‹")
        
        for anchor in anchors:
            logger.info(f"  {anchor['model_name']:30s} - {anchor['source']:15s} - {anchor.get('category', 'unknown')}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡çº¹
        with_fingerprints = [a for a in anchors if 'fingerprint' in a]
        logger.info(f"âœ“ æœ‰æŒ‡çº¹çš„é”šç‚¹: {len(with_fingerprints)}/{len(anchors)}")
        
        return len(anchors) >= 3
        
    except Exception as e:
        logger.error(f"âœ— é”šç‚¹æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_similarity_calculation():
    """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—"""
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯• 3: ç›¸ä¼¼åº¦è®¡ç®—é€»è¾‘")
    logger.info("="*80)
    
    try:
        from src.attribution.similarity import compare_fingerprints
        
        # åˆ›å»ºæµ‹è¯•æŒ‡çº¹ï¼ˆåªæœ‰ logitï¼Œæ²¡æœ‰ refusalï¼‰
        fp1 = {
            "logit_fingerprint": {
                "vector": [0.1, 0.2, 0.3, 0.4, 0.5]
            }
        }
        fp2 = {
            "logit_fingerprint": {
                "vector": [0.1, 0.2, 0.3, 0.4, 0.5]
            }
        }
        
        result = compare_fingerprints(fp1, fp2)
        
        logger.info(f"Logit ç›¸ä¼¼åº¦: {result['logit_similarity']['ensemble_score']:.4f}")
        logger.info(f"æ•´ä½“ç›¸ä¼¼åº¦: {result['overall_similarity']:.4f}")
        
        # éªŒè¯ï¼šå½“åªæœ‰ logit æ—¶ï¼Œoverall_similarity åº”è¯¥ç­‰äº logit_similarity
        logit_score = result['logit_similarity']['ensemble_score']
        overall_score = result['overall_similarity']
        
        if abs(logit_score - overall_score) < 0.0001:
            logger.success("âœ“ ç›¸ä¼¼åº¦è®¡ç®—é€»è¾‘æ­£ç¡®ï¼ˆæ—  refusal æ—¶ä½¿ç”¨ logit åˆ†æ•°ï¼‰")
            return True
        else:
            logger.error(f"âœ— ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: logit={logit_score}, overall={overall_score}")
            return False
        
    except Exception as e:
        logger.error(f"âœ— ç›¸ä¼¼åº¦è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯• 4: æ¨¡å‹åŠ è½½ï¼ˆTransformersï¼‰")
    logger.info("="*80)
    
    try:
        from src.utils.unified_loader import load_model
        
        # æµ‹è¯• GPT-2ï¼ˆè½»é‡çº§æ¨¡å‹ï¼‰
        logger.info("åŠ è½½ GPT-2 æ¨¡å‹...")
        model, tokenizer = load_model("gpt2", engine="transformers")
        
        logger.success("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•æ¨ç†
        logger.info("æµ‹è¯•æ¨ç†...")
        test_text = "Hello, world!"
        inputs = tokenizer(test_text, return_tensors="pt")
        outputs = model(**inputs)
        
        logger.info(f"âœ“ æ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {outputs.logits.shape}")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_fingerprint_extraction():
    """æµ‹è¯•æŒ‡çº¹æå–"""
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯• 5: æŒ‡çº¹æå–")
    logger.info("="*80)
    
    try:
        from src.fingerprint import extract_fingerprint
        from src.utils.unified_loader import load_model
        
        # åŠ è½½æ¨¡å‹
        logger.info("åŠ è½½ GPT-2 æ¨¡å‹...")
        model, tokenizer = load_model("gpt2", engine="transformers")
        
        # åŠ è½½å°‘é‡æ¢é’ˆè¿›è¡Œæµ‹è¯•
        probe_file = Path("data/probes/all_probes.json")
        with open(probe_file, 'r', encoding='utf-8') as f:
            all_probes = json.load(f)
        
        # åªä½¿ç”¨å‰ 10 ä¸ªæ¢é’ˆ
        test_probes = all_probes[:10]
        logger.info(f"ä½¿ç”¨ {len(test_probes)} ä¸ªæ¢é’ˆè¿›è¡Œæµ‹è¯•...")
        
        # æå–æŒ‡çº¹
        fingerprint = extract_fingerprint(model, tokenizer, test_probes, engine="transformers")
        
        logger.info(f"âœ“ æŒ‡çº¹æå–æˆåŠŸ")
        logger.info(f"  Logit ç‰¹å¾æ•°: {len(fingerprint.get('logit_fingerprint', {}).get('vector', []))}")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— æŒ‡çº¹æå–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_attribution_flow():
    """æµ‹è¯•å®Œæ•´çš„æº¯æºæµç¨‹"""
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯• 6: å®Œæ•´æº¯æºæµç¨‹ï¼ˆGPT-2 è‡ªæˆ‘å¯¹æ¯”ï¼‰")
    logger.info("="*80)
    
    try:
        from src.fingerprint import extract_fingerprint
        from src.attribution.similarity import compare_fingerprints
        from src.utils.unified_loader import load_model
        
        # åŠ è½½æ¨¡å‹
        logger.info("åŠ è½½ GPT-2 æ¨¡å‹...")
        model, tokenizer = load_model("gpt2", engine="transformers")
        
        # åŠ è½½æ¢é’ˆ
        probe_file = Path("data/probes/all_probes.json")
        with open(probe_file, 'r', encoding='utf-8') as f:
            all_probes = json.load(f)
        
        # ä½¿ç”¨ 30 ä¸ªæ¢é’ˆ
        test_probes = all_probes[:30]
        logger.info(f"ä½¿ç”¨ {len(test_probes)} ä¸ªæ¢é’ˆ...")
        
        # æå–æŒ‡çº¹
        logger.info("æå–æŒ‡çº¹...")
        fp1 = extract_fingerprint(model, tokenizer, test_probes, engine="transformers")
        fp2 = extract_fingerprint(model, tokenizer, test_probes, engine="transformers")
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        logger.info("è®¡ç®—ç›¸ä¼¼åº¦...")
        result = compare_fingerprints(fp1, fp2)
        
        overall_sim = result['overall_similarity']
        logger.info(f"âœ“ æ•´ä½“ç›¸ä¼¼åº¦: {overall_sim:.4f}")
        
        # GPT-2 å¯¹æ¯”è‡ªå·±åº”è¯¥æ˜¯ 1.0
        if overall_sim >= 0.99:
            logger.success("âœ“ GPT-2 è‡ªæˆ‘å¯¹æ¯”ç›¸ä¼¼åº¦æ­£ç¡®ï¼ˆ>= 0.99ï¼‰")
            return True
        else:
            logger.warning(f"âš  GPT-2 è‡ªæˆ‘å¯¹æ¯”ç›¸ä¼¼åº¦åä½: {overall_sim:.4f}")
            return False
        
    except Exception as e:
        logger.error(f"âœ— æº¯æºæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    logger.info("="*80)
    logger.info("å…¨é¢ç³»ç»Ÿæµ‹è¯•")
    logger.info("="*80)
    
    tests = [
        ("æ¢é’ˆåŠ è½½", test_probe_loading),
        ("é”šç‚¹æ•°æ®åº“", test_anchor_database),
        ("ç›¸ä¼¼åº¦è®¡ç®—", test_similarity_calculation),
        ("æ¨¡å‹åŠ è½½", test_model_loading),
        ("æŒ‡çº¹æå–", test_fingerprint_extraction),
        ("å®Œæ•´æº¯æºæµç¨‹", test_attribution_flow),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            logger.error(f"æµ‹è¯• '{test_name}' å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results[test_name] = False
    
    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info("="*80)
    
    passed = 0
    failed = 0
    for test_name, result in results.items():
        status = "âœ“ PASS" if result else "âœ— FAIL"
        logger.info(f"{status:10s} - {test_name}")
        if result:
            passed += 1
        else:
            failed += 1
    
    logger.info("-"*80)
    logger.info(f"é€šè¿‡: {passed}/{len(tests)}")
    logger.info(f"å¤±è´¥: {failed}/{len(tests)}")
    
    if failed == 0:
        logger.success("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        return 0
    else:
        logger.error(f"\nâŒ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())
