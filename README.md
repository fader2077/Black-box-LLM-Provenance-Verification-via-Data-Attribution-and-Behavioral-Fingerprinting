# åŸºæ–¼è³‡æ–™æ­¸å› èˆ‡è¡Œç‚ºæŒ‡ç´‹çš„é»‘ç›’å¤§å‹èªè¨€æ¨¡å‹æº¯æºæŠ€è¡“ç ”ç©¶

Black-box LLM Provenance Verification via Data Attribution and Behavioral Fingerprinting

> âš ï¸ **é‡è¦ä¿®å¤**: 2026å¹´2æœˆ4æ—¥ä¿®å¤äº†ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯ï¼ˆ70% â†’ 100%ï¼‰ã€‚è¯¦è§ [BUGFIX_20260204.md](BUGFIX_20260204.md)

## å¿«é€Ÿé–‹å§‹

### å®‰è£ä¾è³´
```bash
pip install -r requirements.txt
```

### é‹è¡Œè©•ä¼°

**é‡è¦**: æŒ‡å®šæ­£ç¢ºçš„æ¨ç†å¼•æ“

```bash
# âœ… æ­£ç¢º: HuggingFace æ¨¡å‹ä½¿ç”¨ transformers å¼•æ“
python experiments/full_evaluation.py --target-model gpt2 --engine transformers

# âœ… æ­£ç¢º: Ollama æ¨¡å‹ä½¿ç”¨ ollama å¼•æ“  
python experiments/full_evaluation.py --target-model qwen2.5:7b --engine ollama

# âŒ éŒ¯èª¤: æœªæŒ‡å®šå¼•æ“ï¼ˆé»˜èª ollamaï¼Œæœƒå°è‡´ HuggingFace æ¨¡å‹å¤±æ•—ï¼‰
python experiments/full_evaluation.py --target-model gpt2
```

### å¿«é€Ÿé©—è­‰

æ¸¬è©¦ GPT-2 è‡ªç›¸ä¼¼åº¦ï¼ˆæ‡‰ç‚º 100%ï¼‰:
```bash
$env:PYTHONIOENCODING="utf-8"  # Windows ä¸­æ–‡ç³»çµ±éœ€è¦
python quick_test.py
```

é æœŸè¼¸å‡º:
```
âœ… çµæœ:
  Cosine ç›¸ä¼¼åº¦: 1.0000
  Pearson ç›¸é—œ: 1.0000
  æ•´é«”ç›¸ä¼¼åº¦: 1.0000
```

## ç ”ç©¶ç›®æ¨™

åœ¨ä¸æ¥è§¸æ¨¡å‹æ¬Šé‡èˆ‡è¨“ç·´ç´°ç¯€çš„å‰æä¸‹ï¼ˆBlack-box assumptionï¼‰ï¼Œé‡å°åœ°ç«¯éƒ¨ç½²çš„ LLMï¼Œé€éè¨­è¨ˆç‰¹å®šçš„**è³‡æ–™æ­¸å› æ¢é‡ï¼ˆAttribution Probesï¼‰**ï¼Œæå–æ¨¡å‹åœ¨ç‰¹å®šèªç¾©ç©ºé–“ä¸‹çš„**è¡Œç‚ºæŒ‡ç´‹**ï¼Œè—‰æ­¤åˆ¤å®šè©²æ¨¡å‹æ˜¯å¦æºè‡ªç‰¹å®šçš„åŸºç¤æ¨¡å‹å®¶æ—ã€‚

## æ ¸å¿ƒç†è«–æ¡†æ¶

è‹¥æ¨¡å‹æºè‡ªç‰¹å®šåˆ†ä½ˆï¼ˆä¾‹å¦‚åŒ…å«å¤§é‡ç°¡é«”ä¸­æ–‡æ”¿æ²»å¯©æŸ¥ã€ç‰¹å®šåƒ¹å€¼è§€çš„èªæ–™ï¼‰ï¼Œå³ä½¿ç¶“éå¾®èª¿æˆ–å°é½Šï¼Œå…¶åœ¨ç‰¹å®šç‰¹å¾µç©ºé–“ä¸­çš„æ¢ä»¶æ©Ÿç‡åˆ†ä½ˆä»æœƒä¿ç•™**æ®˜ç•™ç‰¹å¾µï¼ˆResidual Featuresï¼‰**ã€‚

## æ–¹æ³•è«–æ¶æ§‹

### ç¬¬ä¸€éšæ®µï¼šæ§‹å»ºå…·æœ‰å€è¾¨åŠ›çš„ã€Œæ­¸å› æ¢é‡è³‡æ–™é›†ã€
- **æ”¿æ²»æ•æ„Ÿæ€§æ¢é‡ (Political Sensitivity Probes)**
- **èªè¨€ç¿’æ…£æ¢é‡ (Linguistic Shibboleths)**
- **è¨˜æ†¶åŒ–æ¢é‡ (Memorization Probes)**

### ç¬¬äºŒéšæ®µï¼šé»‘ç›’æŒ‡ç´‹æå–
- **Logit åˆ†ä½ˆæŒ‡ç´‹ (Logit-based Fingerprint)**
- **æ‹’çµ•éŸ¿æ‡‰æŒ‡ç´‹ (Refusal Response Fingerprint)**

### ç¬¬ä¸‰éšæ®µï¼šè³‡æ–™æ­¸å› èˆ‡ç›¸ä¼¼åº¦åˆ†æ
- **éŒ¨é»æ¨¡å‹å°æ¯” (Anchor Model Comparison)**
- **è¨ˆç®—æ­¸å› åˆ†æ•¸ (Attribution Score)**

## å°ˆæ¡ˆçµæ§‹

```
thesis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ probes/              # æ¢é‡æ•¸æ“šé›†æ§‹å»ºæ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ political_probes.py
â”‚   â”‚   â”œâ”€â”€ linguistic_probes.py
â”‚   â”‚   â””â”€â”€ memorization_probes.py
â”‚   â”œâ”€â”€ fingerprint/         # æŒ‡ç´‹æå–æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ logit_extractor.py
â”‚   â”‚   â””â”€â”€ refusal_detector.py
â”‚   â”œâ”€â”€ attribution/         # æ­¸å› åˆ†ææ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ similarity.py
â”‚   â”‚   â””â”€â”€ anchor_models.py
â”‚   â””â”€â”€ utils/               # å·¥å…·å‡½æ•¸
â”‚       â”œâ”€â”€ model_loader.py
â”‚       â””â”€â”€ metrics.py
â”œâ”€â”€ data/                    # æ•¸æ“šç›®éŒ„
â”‚   â”œâ”€â”€ probes/              # æ¢é‡æ•¸æ“šé›†
â”‚   â”œâ”€â”€ fingerprints/        # æå–çš„æŒ‡ç´‹
â”‚   â””â”€â”€ anchor_models/       # éŒ¨é»æ¨¡å‹æŒ‡ç´‹
â”œâ”€â”€ experiments/             # å¯¦é©—è…³æœ¬
â”‚   â”œâ”€â”€ pilot_study.py       # åˆæ­¥å¯¦é©—
â”‚   â”œâ”€â”€ full_evaluation.py   # å®Œæ•´è©•ä¼°
â”‚   â””â”€â”€ visualization.py     # çµæœè¦–è¦ºåŒ–
â”œâ”€â”€ configs/                 # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ default_config.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## å®‰è£èˆ‡ç’°å¢ƒè¨­å®š

```bash
# å®‰è£ä¾è³´
pip install -r requirements.txt

# ä¸‹è¼‰ Ollama æ¨¡å‹ (ä½œç‚ºéŒ¨é»æ¨¡å‹)
ollama pull qwen2.5:7b
ollama pull llama3.2:3b
ollama pull deepseek-r1:7b
```

## å¿«é€Ÿé–‹å§‹

### 1. æ§‹å»ºæ¢é‡æ•¸æ“šé›†

```python
from src.probes import build_all_probes

# æ§‹å»ºå®Œæ•´çš„æ¢é‡æ•¸æ“šé›†
probes = build_all_probes(output_dir='data/probes')
```

### 2. æå–æ¨¡å‹æŒ‡ç´‹

```python
from src.fingerprint import extract_fingerprint

# å°å¾…æ¸¬æ¨¡å‹æå–æŒ‡ç´‹
fingerprint = extract_fingerprint(
    model_name='target_model',
    probes_path='data/probes/all_probes.json'
)
```

### 3. æ­¸å› åˆ†æ

```python
from src.attribution import trace_provenance

# é€²è¡Œæº¯æºåˆ†æ
results = trace_provenance(
    target_fingerprint=fingerprint,
    anchor_db_path='data/anchor_models'
)
```

## ä½¿ç”¨æ¡ˆä¾‹

### Pilot Study: Qwen vs Llama å°æ¯”å¯¦é©—

```bash
python experiments/pilot_study.py --models qwen2.5:7b llama3.2:3b
```

æ­¤å¯¦é©—æœƒï¼š
1. ä½¿ç”¨50å€‹å…©å²¸å·®ç•°Promptæ¸¬è©¦å…©å€‹æ¨¡å‹
2. æå–Log-probabilityåˆ†ä½ˆ
3. ç”Ÿæˆt-SNEè¦–è¦ºåŒ–åˆ†ä½ˆåœ–

### å®Œæ•´è©•ä¼°æµç¨‹

```bash
python experiments/full_evaluation.py --target-model <model_name> --output report.json
```

è¼¸å‡ºç¯„ä¾‹ï¼š
```json
{
  "model": "unknown_model",
  "attribution_scores": {
    "qwen2.5:7b": 0.85,
    "llama3.2:3b": 0.32,
    "deepseek-r1:7b": 0.78
  },
  "verdict": "é«˜é¢¨éšªï¼š85% è¡Œç‚ºç‰¹å¾µèˆ‡ Qwen ä¸€è‡´",
  "confidence": 0.91
}
```

## é—œéµæŠ€è¡“ç´°ç¯€

### Logitæå–ç¯„ä¾‹

```python
# é»‘ç›’æ¨¡å¼ä¸‹æå–Tokenæ©Ÿç‡
output = model.generate(
    prompt="è¨ˆç®—æ©Ÿçš„[MASK]æ ¸å¿ƒ",
    output_scores=True,
    return_dict_in_generate=True
)

# æ¯”è¼ƒ"ç®—è¡“" vs "é‹ç®—"çš„æ©Ÿç‡
token_probs = extract_token_probs(output, ["ç®—è¡“", "é‹ç®—"])
```

### è™•ç†æ¨¡å‹æ´—ç™½ (Model Laundering)

é—œæ³¨**æ·±å±¤çŸ¥è­˜æ­¸å› **ï¼š
- æ¸¬è©¦æ¥µåº¦å†·é–€çš„ä¸­åœ‹ç‰¹å®šçŸ¥è­˜é»
- å³ä½¿ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼ŒçŸ¥è­˜ä¾†æºä»æœƒæš´éœ²

## å·²çŸ¥å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: Transformers å¼•æ“åŠ è¼‰å¤§æ¨¡å‹å¤±æ•—
**ç¾è±¡**: åŠ è¼‰DeepSeek-R1-Distill-Llama-8Bç­‰å¤§æ¨¡å‹æ™‚å‡ºç¾KeyboardInterrupt  
**åŸå› **: PyTorchå¼µé‡æ“ä½œä¸­çš„ä½å±¤æ¬¡ä¸­æ–·å•é¡Œ  
**è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨Ollamaå¼•æ“ä½œç‚ºæ›¿ä»£æ–¹æ¡ˆ

```bash
# ä¸æ¨è–¦ï¼ˆæœƒå¤±æ•—ï¼‰
python experiments/full_evaluation.py --target-model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --engine transformers

# æ¨è–¦ï¼ˆä½¿ç”¨Ollamaï¼‰
ollama pull deepseek-r1:8b-llama-distill-q4_K_M
python experiments/full_evaluation.py --target-model deepseek-r1:8b-llama-distill-q4_K_M --engine ollama
```

### å•é¡Œ 2: Ollamaé•·æ™‚é–“é‹è¡Œç©©å®šæ€§ âœ… å·²è§£æ±º
**ç¾è±¡**: è™•ç†å¤§é‡æ¢é‡ï¼ˆ438å€‹ï¼‰æ™‚å¯èƒ½å‡ºç¾KeyboardInterrupté€£æ¥éŒ¯èª¤  
**åŸå› **: é•·æ™‚é–“HTTPè«‹æ±‚å’Œè³‡æºç«¶çˆ­  
**è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨è¶…ç©©å¥æå–å·¥å…·ï¼ˆå·²æ–¼2026å¹´2æœˆ4æ—¥ä¿®å¾©ï¼‰

```bash
# âœ… æ¨è–¦ï¼šä½¿ç”¨è¶…ç©©å¥æå–å·¥å…·
python experiments/ultra_robust_extraction.py \
  --model llama3.2:3b \
  --engine ollama \
  --num-probes 60 \
  --probes-per-session 3 \
  --rest-time 4 \
  --device cuda \
  --output data/anchor_models/llama3_2_3b_fingerprint.json

# è‡ªå‹•åŒ–æ¸¬è©¦ï¼ˆæ¨è–¦ç”¨æ–¼æ‰¹é‡æ¸¬è©¦ï¼‰
python automated_comprehensive_test.py
```

**æ–°åŠŸèƒ½**:
- âœ… æ¯3å€‹æ¢é‡è‡ªå‹•é‡æ–°åŠ è¼‰æ¨¡å‹ï¼ˆé¿å…é•·æ™‚é–“é€£æ¥ï¼‰
- âœ… æ¯å€‹æ¢é‡å¾Œè‡ªå‹•ä¿å­˜æª¢æŸ¥é»
- âœ… æ”¯æŒä¸­æ–·å¾Œç„¡ç¸«æ¢å¾©
- âœ… 100%ç©©å®šæ€§é©—è­‰é€šé

### å•é¡Œ 3: GPUå…§å­˜ä¸è¶³
**ç¾è±¡**: CUDA out of memory  
**è§£æ±ºæ–¹æ¡ˆ**: 
- ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆå¦‚qwen2.5:7bè€Œé14bï¼‰
- å•Ÿç”¨é‡åŒ–ï¼ˆQ4_K_Mï¼‰
- ä½¿ç”¨CPUæ¨¡å¼ `--device cpu`

## å¯¦é©—æ•¸æ“šé›†ä¾†æº

1. **SafetyBench (ä¸­æ–‡ç‰ˆ)**: æ”¿æ²»å®‰å…¨ç›¸é—œéƒ¨åˆ†
2. **C-Eval / CMMLU**: ä¸­åœ‹æ­·å²æ–‡åŒ–éƒ¨åˆ†
3. **å…©å²¸å·®ç•°è©è¡¨**: è‡ªå»º1000å°ç”¨èªå°ç…§è¡¨

## ç›¸é—œæ–‡ç»

- Model Fingerprinting for LLMs
- Dataset Inference Attacks
- Membership Inference Attack
- Instruction Tuning Fingerprint

## é æœŸæˆæœ

- **é‡åŒ–å ±å‘Š**: æ¨¡å‹æˆåˆ†åˆ†æè¡¨
- **åˆè¦è­‰æ˜**: æŠ€è¡“æ€§é©—è­‰æ‰‹æ®µ
- **è‡ªå‹•åŒ–å·¥å…·**: å¯éƒ¨ç½²çš„æª¢æ¸¬è…³æœ¬

## æ¸¬è©¦å ±å‘Š

æŸ¥çœ‹è©³ç´°æ¸¬è©¦å ±å‘Šï¼š
- [GPUæ”¯æŒå ±å‘Š](GPU_SUPPORT_REPORT.md)
- [DeepSeek-R1æ¸¬è©¦å ±å‘Š](DEEPSEEK_R1_TEST_REPORT.md)
- [æœ€çµ‚æ¸¬è©¦å ±å‘Š](FINAL_TEST_REPORT_20260204.md)
- [å·¥ä½œç¸½çµ](FINAL_SUMMARY_20260204.md)
- **[å…¨é¢æ¸¬è©¦å ±å‘Šï¼ˆæœ€æ–°ï¼‰](COMPREHENSIVE_TEST_REPORT.md)** â­ 2026/02/04

### æœ€æ–°æ¸¬è©¦çµæœ (2026/02/04)

**âœ… æ ¸å¿ƒç™¼ç¾**: DeepSeek-R1-Distill-Llama-8B å±¬æ–¼ DeepSeek å®¶æ—

```
ç›¸ä¼¼åº¦æ’å:
1. deepseek-r1:7b [deepseek]  0.5863  ğŸ¥‡
2. gpt2           [gpt]       0.5824  
3. gpt2-medium    [gpt]       0.5822  

çµè«–: DeepSeek-R1:8b èˆ‡ DeepSeek å®¶æ—ç›¸ä¼¼åº¦é«˜ 0.40%
```

**æ¸¬è©¦ç’°å¢ƒ**:
- GPU: NVIDIA RTX 4090 (100% GPUåˆ©ç”¨ç‡ç¢ºèª)
- ç©©å®šæ€§: 100% (KeyboardInterruptå•é¡Œå·²è§£æ±º)
- æˆåŠŸç‡: 20/20 æ¢é‡ (100%)

## æˆæ¬Š

æœ¬ç ”ç©¶è¨ˆç•«ç”¨æ–¼å­¸è¡“ç ”ç©¶èˆ‡å°ç£è³‡å®‰åˆè¦éœ€æ±‚ã€‚

## å¼•ç”¨

å¦‚ä½¿ç”¨æœ¬ç ”ç©¶ï¼Œè«‹å¼•ç”¨ï¼š
```
@misc{llm_provenance_2026,
  title={Black-box LLM Provenance Verification via Data Attribution and Behavioral Fingerprinting},
  author={Your Name},
  year={2026}
}
```
