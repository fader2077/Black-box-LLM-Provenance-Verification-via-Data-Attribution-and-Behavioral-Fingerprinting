# DeepSeek-R1 ç³»åˆ—æµ‹è¯•æŠ¥å‘Š

æ—¥æœŸ: 2026-02-04
æµ‹è¯•ç›®æ ‡: ç¡®å®š DeepSeek-R1-Distill-Llama-8B æ¨¡å‹çš„è°±ç³»ï¼ˆllama vs deepseekï¼‰

## æµ‹è¯•é…ç½®

- **GPU**: NVIDIA GeForce RTX 4090 (24GB VRAM)
- **æ¨ç†å¼•æ“**: Ollama
- **æ¢é’ˆæ•°é‡**: 
  - å¿«é€Ÿæµ‹è¯•: 50 ä¸ªæ¢é’ˆ
  - å®Œæ•´æµ‹è¯•: 438 ä¸ªæ¢é’ˆ
- **é”šç‚¹æ¨¡å‹**: 
  - gpt2 (OpenAI GPT-2, 124M)
  - gpt2-medium (OpenAI GPT-2-Medium, 355M)
  - deepseek-r1:7b (DeepSeek-R1, 7B)
  - llama3.2:3b (Meta Llama 3.2, 3B) - æ­£åœ¨æ·»åŠ 

## æµ‹è¯•æ¨¡å‹

### 1. deepseek-r1:7b
- **çŠ¶æ€**: âœ“ å·²ä½œä¸ºé”šç‚¹æ¨¡å‹
- **æ¥æº**: DeepSeek
- **å‚æ•°**: 7B

### 2. deepseek-r1:8b
- **çŠ¶æ€**: ğŸ”„ æµ‹è¯•ä¸­
- **æ¥æº**: DeepSeek
- **å‚æ•°**: 8B

### 3. deepseek-r1:8b-llama-distill-q4_K_M
- **çŠ¶æ€**: â³ å¾…æµ‹è¯•
- **æ¥æº**: DeepSeek (Llama Distilled)
- **å‚æ•°**: 8B (é‡åŒ– 4-bit)
- **è¯´æ˜**: æœ€æ¥è¿‘ç”¨æˆ·è¦æ±‚çš„ DeepSeek-R1-Distill-Llama-8B

## æµ‹è¯•ç»“æœ

### å¿«é€Ÿæµ‹è¯• (50 æ¢é’ˆ)

#### deepseek-r1:8b

ç›¸ä¼¼åº¦æ’å:
- [ ] vs gpt2: 
- [ ] vs gpt2-medium: 
- [ ] vs deepseek-r1:7b:
- [ ] vs llama3.2:3b:

ç»“è®º: 

---

#### deepseek-r1:8b-llama-distill

ç›¸ä¼¼åº¦æ’å:
- [ ] vs gpt2: 
- [ ] vs gpt2-medium: 
- [ ] vs deepseek-r1:7b:
- [ ] vs llama3.2:3b:

ç»“è®º:

---

### å®Œæ•´æµ‹è¯• (438 æ¢é’ˆ)

#### deepseek-r1:8b

ç›¸ä¼¼åº¦æ’å:
- [ ] vs gpt2: 
- [ ] vs gpt2-medium: 
- [ ] vs deepseek-r1:7b:
- [ ] vs llama3.2:3b:

ç»“è®º:

---

#### deepseek-r1:8b-llama-distill

ç›¸ä¼¼åº¦æ’å:
- [ ] vs gpt2: 
- [ ] vs gpt2-medium: 
- [ ] vs deepseek-r1:7b:
- [ ] vs llama3.2:3b:

ç»“è®º:

---

## å…¶ä»–æ¨¡å‹æµ‹è¯•

### qwen2.5:7b
- **çŠ¶æ€**: 
- **ç»“æœ**:

### gemma2:2b
- **çŠ¶æ€**: 
- **ç»“æœ**:

### llama3.2:3b
- **çŠ¶æ€**: 
- **ç»“æœ**:

---

## æ€»ç»“

### ä¸»è¦å‘ç°

1. **DeepSeek-R1-Distill-Llama-8B è°±ç³»åˆ¤å®š**:
   - 

2. **æ¨¡å‹ç›¸ä¼¼åº¦æ¨¡å¼**:
   -

3. **ç³»ç»Ÿæ€§èƒ½**:
   - GPU åˆ©ç”¨ç‡:
   - å¹³å‡æ¨ç†æ—¶é—´/æ¢é’ˆ:
   - æ€»æµ‹è¯•æ—¶é—´:

### æŠ€æœ¯é—®é¢˜

1. **å·²è§£å†³**:
   - GPT-2 è‡ªæˆ‘ç›¸ä¼¼åº¦ 70% â†’ 100% âœ“
   - GPU æ”¯æŒå®ç° âœ“
   - Unicode ç¼–ç é—®é¢˜ âœ“

2. **å·²çŸ¥é—®é¢˜**:
   - Transformers å¼•æ“ KeyboardInterrupt (DeepSeek-R1-Distill-Llama-8B åŠ è½½å¤±è´¥)
   - Ollama API ä¸æ”¯æŒ logprobs (ä½¿ç”¨å¯å‘å¼ç‰¹å¾)

3. **è§£å†³æ–¹æ¡ˆ**:
   - ä½¿ç”¨ Ollama å¼•æ“ä½œä¸ºæ›¿ä»£
   - ä½¿ç”¨ deepseek-r1:8b-llama-distill-q4_K_M (é‡åŒ–ç‰ˆæœ¬)

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

- [ ] å®Œæˆæ‰€æœ‰å¿«é€Ÿæµ‹è¯•
- [ ] æ‰§è¡Œå®Œæ•´æµ‹è¯•ï¼ˆå¦‚æœéœ€è¦ï¼‰
- [ ] æ›´æ–° README æ–‡æ¡£
- [ ] æ¨é€åˆ° GitHub

---

## é™„å½•

### å‘½ä»¤è®°å½•

```bash
# æ·»åŠ  llama3.2:3b é”šç‚¹
python add_llama_anchor.py

# å¿«é€Ÿæµ‹è¯• deepseek-r1:8b
python experiments/quick_evaluation.py --target-model deepseek-r1:8b --engine ollama --num-probes 50

# å¿«é€Ÿæµ‹è¯• deepseek-r1:8b-llama-distill
python experiments/quick_evaluation.py --target-model deepseek-r1:8b-llama-distill-q4_K_M --engine ollama --num-probes 50
```

### æµ‹è¯•æ—¥å¿—è·¯å¾„

- å¿«é€Ÿæµ‹è¯•æ—¥å¿—: `logs/quick_evaluation_*.log`
- å®Œæ•´æµ‹è¯•æ—¥å¿—: `results/evaluation_*.json`
