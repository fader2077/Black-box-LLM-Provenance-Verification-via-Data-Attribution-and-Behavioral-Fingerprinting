# Ollama Logprobs é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## é—®é¢˜æ¦‚è¿°

ç»è¿‡æ·±å…¥æµ‹è¯•ï¼Œå‘ç°äº†ä¸€ä¸ªå…³é”®æŠ€æœ¯é™åˆ¶ï¼š

**Ollama API ä¸æ”¯æŒ logprobs è¾“å‡º**

è¿™å¯¼è‡´ï¼š
1. ä½¿ç”¨ Ollama å¼•æ“æå–çš„æ‰€æœ‰æŒ‡çº¹éƒ½æ˜¯**å¯å‘å¼ç‰¹å¾**ï¼ˆåŸºäºå“åº”é•¿åº¦ã€å­—ç¬¦å¤šæ ·æ€§ç­‰ï¼‰ï¼Œè€ŒéçœŸå®çš„ token logits
2. é”šç‚¹æ¨¡å‹æŒ‡çº¹ï¼ˆLlama3.2:3b, Llama3.1:8bï¼‰å…¨ä¸º0æˆ–å¸¸æ•°
3. ç›®æ ‡æ¨¡å‹æŒ‡çº¹ï¼ˆDeepSeek-R1-Distill-Llama-8Bï¼‰ä¹Ÿæ˜¯å¯å‘å¼å€¼
4. ç›¸ä¼¼åº¦è®¡ç®—æ— æ„ä¹‰ï¼ˆéƒ½æ˜¯ -0.02 å·¦å³çš„è´Ÿå€¼ï¼‰

## éªŒè¯ç»“æœ

### é”šç‚¹æŒ‡çº¹æœ‰æ•ˆæ€§æ£€æŸ¥

```
âœ… æœ‰æ•ˆ gpt2_fingerprint.json
   æ¨¡å‹: gpt2
   ç»´åº¦: 1110, éé›¶å€¼: 1110/1110
   èŒƒå›´: [-0.675, 2.260]
   å¼•æ“: transformers

âœ… æœ‰æ•ˆ gpt2_medium_fingerprint.json
   æ¨¡å‹: gpt2-medium
   ç»´åº¦: 1110, éé›¶å€¼: 1110/1110
   èŒƒå›´: [-0.724, 2.329]
   å¼•æ“: transformers

âœ… æœ‰æ•ˆ deepseek_r1_7b_fingerprint.json
   æ¨¡å‹: deepseek-r1:7b
   ç»´åº¦: 1110, éé›¶å€¼: 1110/1110
   èŒƒå›´: [-0.533, 2.018]
   å¼•æ“: transformers/full_evaluation

âŒ å…¨é›¶ llama3_2_3b_fingerprint.json
   æ¨¡å‹: llama3.2:3b
   ç»´åº¦: 200, éé›¶å€¼: 0/200
   èŒƒå›´: [0.000, 0.000]
   å¼•æ“: ollama (å¯å‘å¼)

âŒ å…¨é›¶ llama3_1_8b_fingerprint.json
   æ¨¡å‹: llama3.1:8b
   ç»´åº¦: 200, éé›¶å€¼: 0/200
   èŒƒå›´: [0.000, 0.000]
   å¼•æ“: ollama (å¯å‘å¼)
```

### GPT2 è‡ªç›¸ä¼¼åº¦æµ‹è¯•

```
python quick_test.py

âœ… ç»“æœ:
  Cosine ç›¸ä¼¼åº¦: 1.0000
  Pearson ç›¸å…³: 1.0000
  æ•´ä½“ç›¸ä¼¼åº¦: 1.0000
  
âœ… ç³»ç»Ÿå¯¹ transformers å¼•æ“æ­£å¸¸å·¥ä½œ
```

## æ ¹æœ¬åŸå› 

### Ollama API é™åˆ¶

æŸ¥çœ‹ä»£ç  `src/fingerprint/logit_extractor.py:67`:
```python
elif "logprobs_available" in output and not output["logprobs_available"]:
    logger.debug("Ollama API ä¸æ”¯æ´ logprobsï¼Œä½¿ç”¨åŸºæ–¼å›æ‡‰çš„å•Ÿç™¼å¼ç‰¹å¾µ")
    return self._extract_from_api_response(output.get("text", ""), target_tokens)
```

### å¯å‘å¼ç‰¹å¾å®ç°

æŸ¥çœ‹ `src/fingerprint/logit_extractor.py:309`:
```python
def _extract_from_api_response(self, response, target_tokens):
    """
    ç”±æ–¼ Ollama ä¸æä¾› logprobsï¼Œæˆ‘å€‘ä½¿ç”¨åŸºæ–¼å›æ‡‰çš„å•Ÿç™¼å¼ç‰¹å¾µ
    """
    # è®¡ç®—æ–‡æœ¬ç‰¹å¾ä½œä¸ºå½æœºç‡
    length_feature = min(len(response_text) / 100.0, 1.0)
    diversity_feature = min(unique_chars / 50.0, 1.0)
    chinese_ratio = chinese_chars / max(len(response_text), 1)
    # ...
    return {"top_k_probs": [length_feature, diversity_feature, ...]}
```

è¿™äº›å¯å‘å¼ç‰¹å¾**ä¸æ˜¯çœŸå®çš„æ¨¡å‹è¡Œä¸ºæŒ‡çº¹**ï¼Œæ— æ³•ç”¨äºæº¯æºåˆ†æã€‚

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: HuggingFace Transformers å¼•æ“ âœ… æ¨è

**ä¼˜ç‚¹**:
- âœ… åŸç”Ÿæ”¯æŒ logprobs
- âœ… é«˜è´¨é‡æŒ‡çº¹ï¼ˆ1110ç»´ï¼‰
- âœ… GPU åŠ é€Ÿ
- âœ… å·²éªŒè¯å·¥ä½œæ­£å¸¸ï¼ˆGPT2 100% è‡ªç›¸ä¼¼åº¦ï¼‰

**ç¼ºç‚¹**:
- âŒ éœ€è¦ä¸‹è½½å®Œæ•´æ¨¡å‹ï¼ˆ~16GB for Llama-3.1-8Bï¼‰
- âŒ éœ€è¦ HuggingFace è®¿é—®æƒé™
- âŒ å†…å­˜å ç”¨è¾ƒå¤§

**ä½¿ç”¨æ–¹æ³•**:
```bash
# æå–é”šç‚¹
python experiments/full_evaluation.py \
  --target-model meta-llama/Llama-3.1-8B-Instruct \
  --engine transformers \
  --device cuda

# æµ‹è¯•ç›®æ ‡æ¨¡å‹
python experiments/full_evaluation.py \
  --target-model deepseek-ai/DeepSeek-R1-Distill-Llama-8B \
  --engine transformers \
  --device cuda
```

**æ³¨æ„**: éœ€è¦å…ˆç™»å½• HuggingFace:
```bash
pip install huggingface-hub
huggingface-cli login
```

### æ–¹æ¡ˆ 2: vLLM å¼•æ“ âš¡ é«˜æ€§èƒ½

**ä¼˜ç‚¹**:
- âœ… æ”¯æŒ logprobs API
- âœ… é«˜æ€§èƒ½æ¨ç†
- âœ… GPU ä¼˜åŒ–

**ç¼ºç‚¹**:
- âŒ éœ€è¦å®‰è£… vLLM
- âŒ é…ç½®å¤æ‚

**å®‰è£…**:
```bash
pip install vllm
```

**ä½¿ç”¨**:
```bash
python experiments/full_evaluation.py \
  --target-model meta-llama/Llama-3.1-8B \
  --engine vllm \
  --device cuda
```

### æ–¹æ¡ˆ 3: ä»…ä½¿ç”¨æœ‰æ•ˆé”šç‚¹ ğŸ¯ å®ç”¨æ–¹æ¡ˆ

**ä¼˜ç‚¹**:
- âœ… ç«‹å³å¯ç”¨
- âœ… æ— éœ€é¢å¤–ä¸‹è½½
- âœ… å·²éªŒè¯å·¥ä½œ

**ç¼ºç‚¹**:
- âŒ ç¼ºå°‘ Llama å®¶æ—é”šç‚¹
- âŒ æ¯”è¾ƒèŒƒå›´æœ‰é™

**å½“å‰æœ‰æ•ˆé”šç‚¹**:
- gpt2 (124M) - GPT å®¶æ—
- gpt2-medium (355M) - GPT å®¶æ—
- deepseek-r1:7b (7B) - DeepSeek å®¶æ—

**ä½¿ç”¨æ–¹æ³•**:
```bash
python test_with_valid_anchors.py
```

## æ¨èå·¥ä½œæµç¨‹

### é˜¶æ®µ 1: å¿«é€ŸéªŒè¯ï¼ˆå½“å‰å¯ç”¨ï¼‰

1. **éªŒè¯ç³»ç»Ÿå·¥ä½œ**:
```bash
python quick_test.py  # GPT2 è‡ªç›¸ä¼¼åº¦åº”ä¸º 100%
```

2. **ä½¿ç”¨ç°æœ‰é”šç‚¹æµ‹è¯•**:
```bash
python test_with_valid_anchors.py
```

3. **é™åˆ¶è¯´æ˜**:
   - ä»…èƒ½ä¸ GPT2, DeepSeek-R1:7b æ¯”è¾ƒ
   - ç›®æ ‡æ¨¡å‹éœ€ä½¿ç”¨ transformers å¼•æ“æå–

### é˜¶æ®µ 2: å®Œæ•´æµ‹è¯•ï¼ˆéœ€è¦ HuggingFaceï¼‰

1. **å‡†å¤‡ HuggingFace è®¿é—®**:
```bash
huggingface-cli login
```

2. **æå– Llama é”šç‚¹**:
```bash
python experiments/full_evaluation.py \
  --target-model meta-llama/Llama-3.1-8B-Instruct \
  --engine transformers \
  --device cuda \
  --output data/anchor_models/llama3_1_8b_fingerprint_transformers.json
```

3. **æ›´æ–° metadata.json**:
ç¼–è¾‘ `data/anchor_models/metadata.json`:
```json
{
  "llama3.1:8b": {
    "name": "Llama-3.1-8B-Instruct",
    "source": "meta",
    "category": "llama",
    "fingerprint_file": "data/anchor_models/llama3_1_8b_fingerprint_transformers.json",
    "engine": "transformers",
    "hf_model": "meta-llama/Llama-3.1-8B-Instruct"
  }
}
```

4. **æå–ç›®æ ‡æ¨¡å‹æŒ‡çº¹**:
```bash
python experiments/full_evaluation.py \
  --target-model deepseek-ai/DeepSeek-R1-Distill-Llama-8B \
  --engine transformers \
  --device cuda
```

5. **è¿è¡Œå®Œæ•´åˆ†æ**:
```bash
python complete_provenance_test.py
```

## å½“å‰é¡¹ç›®çŠ¶æ€

### âœ… å·²éªŒè¯å·¥ä½œ
- Transformers å¼•æ“ logprobs æå–
- GPT2 æŒ‡çº¹æå–ï¼ˆ100% è‡ªç›¸ä¼¼åº¦ï¼‰
- ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•
- GPU åŠ é€Ÿ (RTX 4090)

### âš ï¸ æŠ€æœ¯é™åˆ¶
- Ollama ä¸æ”¯æŒ logprobs
- ç°æœ‰ Llama é”šç‚¹æ— æ•ˆï¼ˆä½¿ç”¨ Ollama æå–ï¼‰
- ç›®æ ‡æ¨¡å‹æŒ‡çº¹æ— æ•ˆï¼ˆä½¿ç”¨ Ollama æå–ï¼‰

### ğŸ”„ éœ€è¦å®Œæˆ
- [ ] ä½¿ç”¨ transformers å¼•æ“é‡æ–°æå– Llama é”šç‚¹
- [ ] ä½¿ç”¨ transformers å¼•æ“æå–ç›®æ ‡æ¨¡å‹æŒ‡çº¹
- [ ] æ›´æ–° metadata.json é…ç½®
- [ ] è¿è¡Œå®Œæ•´æµ‹è¯•
- [ ] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
- [ ] æ¨é€åˆ° GitHub

## æ—¶é—´ä¼°ç®—

### å¿«é€Ÿæ–¹æ¡ˆï¼ˆä»…ç°æœ‰é”šç‚¹ï¼‰
- éªŒè¯ç³»ç»Ÿ: 2åˆ†é’Ÿ
- æµ‹è¯•åˆ†æ: 3åˆ†é’Ÿ
- æ–‡æ¡£æ•´ç†: 10åˆ†é’Ÿ
- **æ€»è®¡: 15åˆ†é’Ÿ**

### å®Œæ•´æ–¹æ¡ˆï¼ˆHuggingFaceï¼‰
- ä¸‹è½½ Llama-3.1-8B: 10-30åˆ†é’Ÿ
- æå–é”šç‚¹æŒ‡çº¹: 15-20åˆ†é’Ÿ
- ä¸‹è½½ DeepSeek-R1-Distill: 10-30åˆ†é’Ÿ
- æå–ç›®æ ‡æŒ‡çº¹: 15-20åˆ†é’Ÿ
- è¿è¡Œæµ‹è¯•: 5åˆ†é’Ÿ
- æ–‡æ¡£æ•´ç†: 10åˆ†é’Ÿ
- **æ€»è®¡: 65-115åˆ†é’Ÿ**

## å»ºè®®

åŸºäºå½“å‰æƒ…å†µï¼Œå»ºè®®ï¼š

1. **ç«‹å³å¯è¡Œ**: ä½¿ç”¨æ–¹æ¡ˆ3ï¼ˆç°æœ‰é”šç‚¹ï¼‰è¿›è¡Œåˆæ­¥æµ‹è¯•
2. **æ–‡æ¡£è¯´æ˜**: æ¸…æ¥šæ ‡æ³¨ Ollama é™åˆ¶
3. **æœªæ¥å·¥ä½œ**: åœ¨ README ä¸­è¯´æ˜éœ€è¦ HuggingFace è®¿é—®
4. **æ¨é€ä»£ç **: å…ˆæ¨é€å½“å‰å·¥ä½œæˆæœå’Œæ–‡æ¡£

è¿™æ ·å¯ä»¥ï¼š
- âœ… å±•ç¤ºç³»ç»Ÿæ¶æ„å’Œè®¾è®¡
- âœ… è¯´æ˜æŠ€æœ¯å®ç°å’Œé™åˆ¶
- âœ… æä¾›å®Œæ•´çš„ä½¿ç”¨æŒ‡å—
- âœ… ä¸ºæœªæ¥æ‰©å±•ç•™ä¸‹æ¸…æ™°è·¯å¾„
