"""
å…¨é¢æµ‹è¯•æµç¨‹ - DeepSeek-R1 è°±ç³»åˆ¤å®š
ä½¿ç”¨GPUï¼Œå¸¦å®Œæ•´é”™è¯¯å¤„ç†
"""

import sys
import json
from pathlib import Path
from datetime import datetime
from loguru import logger

sys.path.insert(0, str(Path(__file__).parent))

from src.utils.unified_loader import load_model
from src.attribution.anchor_models import AnchorModelsDatabase
from src.attribution.similarity import SimilarityCalculator
from experiments.robust_fingerprint_extraction import RobustFingerprintExtractor


def comprehensive_test():
    """æ‰§è¡Œå…¨é¢æµ‹è¯•æµç¨‹"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    logger.info("=" * 80)
    logger.info("DeepSeek-R1 è°±ç³»åˆ¤å®š - å…¨é¢æµ‹è¯•")
    logger.info("=" * 80)
    logger.info(f"æ—¶é—´æˆ³: {timestamp}")
    logger.info(f"ä½¿ç”¨è®¾å¤‡: GPU (CUDA)")
    logger.info("=" * 80)
    
    # æµ‹è¯•é…ç½®
    test_models = [
        {
            "name": "deepseek-r1:8b",
            "engine": "ollama",
            "description": "DeepSeek-R1 8BåŸºç¡€ç‰ˆæœ¬"
        },
        {
            "name": "deepseek-r1:8b-llama-distill-q4_K_M",
            "engine": "ollama",
            "description": "DeepSeek-R1-Distill-Llama-8B (é‡åŒ–ç‰ˆæœ¬)"
        }
    ]
    
    num_probes = 100  # ä½¿ç”¨100ä¸ªæ¢é’ˆè¿›è¡Œå¿«é€Ÿä½†å¯é çš„æµ‹è¯•
    batch_size = 5
    
    # åŠ è½½æ¢é’ˆ
    logger.info("\n[æ­¥éª¤ 1/4] åŠ è½½æ¢é’ˆ...")
    probes_path = Path("data/probes/all_probes.json")
    
    if not probes_path.exists():
        logger.error("æ¢é’ˆæ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    with open(probes_path, 'r', encoding='utf-8') as f:
        probes_data = json.load(f)
    
    all_probes = []
    for probe_type, probes in probes_data.items():
        all_probes.extend(probes)
    
    selected_probes = all_probes[:num_probes]
    logger.info(f"âœ“ å·²åŠ è½½ {len(selected_probes)} ä¸ªæ¢é’ˆ")
    
    # åŠ è½½é”šç‚¹æ•°æ®åº“
    logger.info("\n[æ­¥éª¤ 2/4] åŠ è½½é”šç‚¹æ•°æ®åº“...")
    db = AnchorModelsDatabase()
    
    # éªŒè¯é”šç‚¹
    anchors_with_fp = []
    for model_name, data in db.anchor_models.items():
        if data.get("has_fingerprint"):
            fp = db.load_fingerprint(model_name)
            if fp:
                anchors_with_fp.append({
                    "model_id": model_name,
                    "fingerprint": fp,
                    "source": data["metadata"].get("source"),
                    "category": data["metadata"].get("category")
                })
                logger.info(f"  âœ“ {model_name} ({data['metadata'].get('category')})")
    
    logger.info(f"æ€»è®¡: {len(anchors_with_fp)} ä¸ªé”šç‚¹æ¨¡å‹å¯ç”¨")
    
    if len(anchors_with_fp) < 3:
        logger.warning("è­¦å‘Š: é”šç‚¹æ¨¡å‹æ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ¤å®šå‡†ç¡®æ€§")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰llamaé”šç‚¹
    has_llama = any(a['category'] == 'llama' for a in anchors_with_fp)
    has_deepseek = any(a['category'] == 'deepseek' for a in anchors_with_fp)
    
    if not has_llama:
        logger.warning("âš ï¸ è­¦å‘Š: æ²¡æœ‰Llamaé”šç‚¹ï¼Œæ— æ³•åˆ¤å®šä¸Llamaçš„ç›¸ä¼¼åº¦")
    if not has_deepseek:
        logger.warning("âš ï¸ è­¦å‘Š: æ²¡æœ‰DeepSeeké”šç‚¹ï¼Œæ— æ³•åˆ¤å®šä¸DeepSeekçš„ç›¸ä¼¼åº¦")
    
    # ç›¸ä¼¼åº¦è®¡ç®—å™¨
    sim_calc = SimilarityCalculator()
    
    # æµ‹è¯•ç»“æœå­˜å‚¨
    all_results = []
    
    # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
    logger.info(f"\n[æ­¥éª¤ 3/4] æµ‹è¯• {len(test_models)} ä¸ªæ¨¡å‹...")
    
    for idx, test_model_config in enumerate(test_models, 1):
        model_name = test_model_config["name"]
        engine = test_model_config["engine"]
        
        logger.info(f"\n{'='*80}")
        logger.info(f"æµ‹è¯• {idx}/{len(test_models)}: {model_name}")
        logger.info(f"æè¿°: {test_model_config['description']}")
        logger.info(f"{'='*80}")
        
        try:
            # åŠ è½½æ¨¡å‹
            logger.info(f"\n  [3.{idx}.1] åŠ è½½æ¨¡å‹...")
            model = load_model(
                model_name=model_name,
                engine=engine,
                device="cuda"
            )
            logger.info(f"  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æå–æŒ‡çº¹
            logger.info(f"\n  [3.{idx}.2] æå–æŒ‡çº¹...")
            logger.info(f"  æ¢é’ˆæ•°é‡: {num_probes}")
            logger.info(f"  æ‰¹å¤„ç†å¤§å°: {batch_size}")
            logger.info(f"  é¢„è®¡æ—¶é—´: {num_probes * 3.5 / 60:.1f} åˆ†é’Ÿ")
            
            extractor = RobustFingerprintExtractor(
                model=model,
                batch_size=batch_size,
                max_retries=3
            )
            
            fingerprint = extractor.extract_with_retry(
                probes=selected_probes,
                model_id=model_name,
                resume_from_checkpoint=True
            )
            
            if not fingerprint:
                logger.error(f"  âœ— æŒ‡çº¹æå–å¤±è´¥")
                continue
            
            logger.info(f"  âœ“ æŒ‡çº¹æå–æˆåŠŸ")
            logger.info(f"  ç‰¹å¾ç»´åº¦: {fingerprint['logit_fingerprint']['dimension']}")
            
            # ä¿å­˜æŒ‡çº¹
            fp_path = Path(f"results/{model_name.replace(':', '_')}_fingerprint.json")
            fp_path.parent.mkdir(parents=True, exist_ok=True)
            with open(fp_path, 'w', encoding='utf-8') as f:
                json.dump(fingerprint, f, indent=2, ensure_ascii=False)
            logger.info(f"  ä¿å­˜åˆ°: {fp_path}")
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            logger.info(f"\n  [3.{idx}.3] è®¡ç®—ä¸é”šç‚¹çš„ç›¸ä¼¼åº¦...")
            
            similarities = []
            for anchor in anchors_with_fp:
                anchor_id = anchor["model_id"]
                anchor_fp = anchor["fingerprint"]
                
                sim_result = sim_calc.calculate_fingerprint_similarity(fingerprint, anchor_fp)
                score = sim_result["overall_similarity"]
                
                similarities.append({
                    "anchor": anchor_id,
                    "category": anchor["category"],
                    "source": anchor["source"],
                    "similarity": score
                })
                
                logger.info(f"    vs {anchor_id:30s} [{anchor['category']:10s}] {score:.4f}")
            
            # æ’åºç›¸ä¼¼åº¦
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            
            # åˆ¤å®š
            top_match = similarities[0]
            logger.info(f"\n  ğŸ¯ æœ€ç›¸ä¼¼: {top_match['anchor']} ({top_match['similarity']:.4f})")
            logger.info(f"  ğŸ“Š ç±»åˆ«: {top_match['category']}")
            logger.info(f"  ğŸ“ æ¥æº: {top_match['source']}")
            
            # åˆ†ç±»ç»Ÿè®¡
            category_scores = {}
            for sim in similarities:
                cat = sim['category']
                if cat not in category_scores:
                    category_scores[cat] = []
                category_scores[cat].append(sim['similarity'])
            
            category_avg = {cat: sum(scores)/len(scores) for cat, scores in category_scores.items()}
            
            logger.info(f"\n  ğŸ“ˆ ç±»åˆ«å¹³å‡ç›¸ä¼¼åº¦:")
            for cat, avg_score in sorted(category_avg.items(), key=lambda x: x[1], reverse=True):
                logger.info(f"    {cat:15s} {avg_score:.4f}")
            
            # åˆ¤å®šç»“è®º
            if 'llama' in category_avg and 'deepseek' in category_avg:
                llama_score = category_avg['llama']
                deepseek_score = category_avg['deepseek']
                diff = abs(llama_score - deepseek_score)
                
                if llama_score > deepseek_score:
                    verdict = f"æ›´æ¥è¿‘ Llama å®¶æ— (å·®å¼‚: {diff:.4f})"
                else:
                    verdict = f"æ›´æ¥è¿‘ DeepSeek å®¶æ— (å·®å¼‚: {diff:.4f})"
                
                logger.info(f"\n  âš–ï¸  åˆ¤å®š: {verdict}")
            else:
                verdict = "æ— æ³•åˆ¤å®š (ç¼ºå°‘Llamaæˆ–DeepSeeké”šç‚¹)"
                logger.info(f"\n  âš ï¸  {verdict}")
            
            # ä¿å­˜ç»“æœ
            result = {
                "model": model_name,
                "description": test_model_config["description"],
                "timestamp": timestamp,
                "num_probes": num_probes,
                "similarities": similarities,
                "category_averages": category_avg,
                "top_match": top_match,
                "verdict": verdict
            }
            
            all_results.append(result)
            
        except KeyboardInterrupt:
            logger.warning(f"æ£€æµ‹åˆ°ä¸­æ–­ï¼Œä¿å­˜å·²æœ‰ç»“æœ...")
            break
        except Exception as e:
            logger.error(f"  âœ— æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    logger.info(f"\n[æ­¥éª¤ 4/4] ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    report_path = Path(f"results/comprehensive_test_report_{timestamp}.json")
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    report = {
        "timestamp": timestamp,
        "test_config": {
            "num_probes": num_probes,
            "batch_size": batch_size,
            "device": "cuda",
            "anchors": [a["model_id"] for a in anchors_with_fp]
        },
        "results": all_results,
        "summary": {
            "total_models_tested": len(all_results),
            "successful_tests": len(all_results)
        }
    }
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"âœ“ æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
    
    # æ‰“å°æ€»ç»“
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 80)
    
    for result in all_results:
        logger.info(f"\n{result['model']}:")
        logger.info(f"  æœ€ç›¸ä¼¼: {result['top_match']['anchor']} ({result['top_match']['similarity']:.4f})")
        logger.info(f"  åˆ¤å®š: {result['verdict']}")
    
    logger.info("\n" + "=" * 80)
    logger.info("âœ… å…¨é¢æµ‹è¯•å®Œæˆ")
    logger.info("=" * 80)


if __name__ == "__main__":
    comprehensive_test()
